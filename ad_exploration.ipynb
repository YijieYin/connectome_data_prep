{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9c8d0c-771e-4b3e-8b29-a09994f18e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "import re\n",
    "\n",
    "# for making legends \n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.lines as mlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6bdb1d7-45f9-4769-81ea-07aaa80eba1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install bokeh\n",
    "from bokeh.plotting import figure, show, output_notebook\n",
    "from bokeh.models import HoverTool, ColumnDataSource, IndexFilter, Spinner, TextInput, CustomJS, Select, LassoSelectTool, Div, Range1d\n",
    "from bokeh.palettes import Spectral10\n",
    "from bokeh.io import output_file, show, save\n",
    "from bokeh.layouts import layout, column, row\n",
    "from bokeh import events\n",
    "\n",
    "output_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf77448-dfc9-4111-b328-6786331aa9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set font size for tick labels\n",
    "plt.rcParams['xtick.labelsize'] = 14\n",
    "plt.rcParams['ytick.labelsize'] = 14\n",
    "# Set font size for axis labels\n",
    "plt.rcParams['axes.labelsize'] = 16\n",
    "# Set font size for title\n",
    "plt.rcParams['axes.titlesize'] = 22\n",
    "# Set font size for legend labels\n",
    "plt.rcParams['legend.fontsize'] = 12\n",
    "# Adjust the fontsize as needed\n",
    "plt.rcParams['legend.title_fontsize'] = 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a9171c-0ee9-4de5-9064-eb191218df60",
   "metadata": {},
   "outputs": [],
   "source": [
    "savefig = False "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c986246-b762-45bb-927e-66441f805c64",
   "metadata": {
    "tags": []
   },
   "source": [
    "# get axon-dendrite connectome \n",
    "connectivity matrix downloaded [here](https://www.science.org/doi/10.1126/science.add9330)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94023893-d672-4241-a0e4-fc25c3badac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ad = pd.read_csv('/Users/yijieyin/Downloads/larva/Supplementary-Data-S1/ad_connectivity_matrix.csv', index_col=0)\n",
    "ad.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6462e9a2-48bb-4386-ba56-ad904d81ce49",
   "metadata": {},
   "source": [
    "So the columns and rows are skids, and the values are synapse numbers, not input proportion. So we need the total number of synapses on the dendrites for each skid. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c765e26-da14-4e28-aab0-86e0b17b6936",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sum across rows, for each column \n",
    "# ad.sum(axis='rows')\n",
    "# calculate input proportion. Divide for each column \n",
    "ad_inprop = ad.div(ad.sum(axis = 'rows'),axis = 'columns')\n",
    "ad_inprop.fillna(0, inplace=True)\n",
    "# turn index into string from int64 \n",
    "ad_inprop.index = ad_inprop.index.map(str)\n",
    "ad_inprop.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a9970bf-2ea1-48c9-8bb9-157da34222a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# histogram of total number of postsynapses\n",
    "ad.sum(axis = 'rows').hist(bins = 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b81a91-6660-4765-afbc-7bfb74c5b087",
   "metadata": {},
   "source": [
    "# get meta info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6fb5c1e-3f4e-4f66-93cd-4bbb0ed72e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # meta info \n",
    "# meta = pd.read_csv('/Users/yijieyin/Downloads/larva/Supplementary-Data-S2.csv')\n",
    "# meta.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f5d73b9-6ba0-4085-94ee-df473b62ba63",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta = pd.read_csv('/Users/yijieyin/Downloads/larva/brain-neurons_meta-data.csv')\n",
    "meta.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6deb122-17a8-4f46-9f5b-015a02fc3174",
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many cells on one side (roughly)? \n",
    "meta.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165312e8-fb87-4d13-9790-7d009484ddf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# and which types are there? \n",
    "meta.celltype.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40851b6-851f-4980-86d2-230f382c7adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# what about sub-type?\n",
    "meta.annotated_name.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c74fc6e-3265-430d-a918-b165b91b7ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Â how many neurons on the right without a contralateral homologue? \n",
    "sum(meta.leftid == 'no pair')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4daadaba-0ca8-41d3-8327-296ef3524017",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(meta.rightid == 'no pair')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "509eacd0-b460-43e8-837e-ad104a5182c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# which kind of sensory neurons are there? \n",
    "meta[meta.celltype.isin(['sensory'])]['annotated_name'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dfe6a4c-b549-4d92-b0e8-39a708d43133",
   "metadata": {},
   "source": [
    "From Philipp on enteric neurons: \n",
    "[Miroschnikow's thesis](https://bonndoc.ulb.uni-bonn.de/xmlui/handle/20.500.11811/9188)  \n",
    "https://journals.biologists.com/jeb/article/220/10/1774/17783/Pathogen-induced-food-evasion-behavior-in  \n",
    "there's an annotation in catmaid called sugar sensory  \n",
    "the enteric neurons are called AN-L/R_sens etc. AN means antennal nerve"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db6e42dd-2809-4da1-aed5-e7c9789d3d79",
   "metadata": {},
   "source": [
    "## make a type dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a66e5c15-32bf-42f8-a5f1-e32d29442cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# there are many values in the left_id or right_id column that is 'no pair'. So multiple values are assigned to the 'no pair' key. \n",
    "# when this happens, only the last value is retained in the dictionary. \n",
    "# but this is okay because we don't care about the 'no pair' ids. \n",
    "types = dict(zip(pd.concat([meta.leftid, meta.rightid]),\n",
    "                 pd.concat([meta.celltype,meta.celltype])))\n",
    "del types['no pair']\n",
    "# have a look at a few \n",
    "dict(list(types.items())[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "370751c5-a4da-4eaf-81a4-39d438cc1bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# and a neuron name dictionary \n",
    "names = dict(zip(pd.concat([meta.leftid, meta.rightid]),\n",
    "                 pd.concat([meta.left_name,meta.right_name])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e37a88b5-297a-42b7-a8a1-d04d95b2b461",
   "metadata": {},
   "outputs": [],
   "source": [
    "# and a side dictionary \n",
    "sides = dict.fromkeys(meta.leftid, 'left')\n",
    "sides.update(dict.fromkeys(meta.rightid, 'right'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0baea338-f4e4-47d2-b23e-b2eae2eebbe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# additional info from annotated_name column\n",
    "types_add = dict(zip(pd.concat([meta.leftid, meta.rightid]),\n",
    "                 pd.concat([meta.annotated_name,meta.annotated_name])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d28b5d1b-aea3-49de-8b60-ebc51707c6c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the interconnectivity between select neurons \n",
    "selected = [key for key, v in types.items() if (v == 'MBIN') and ('DAN' in types_add[key])]\n",
    "ad_inprop.loc[selected, selected]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93eaa58a-e446-49f1-aecf-181611438e49",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# remove side info and calculate the mean between sides  \n",
    "# names_noside = dict([(skid, re.sub('( left| right|;right|;left|_left|_right|-R-|-L-|l$|r$|l |r )','', name)) for (skid, name) in names.items()])\n",
    "# remove things in brackets\n",
    "names_noside = dict([(skid, re.sub('( left| right|;right|;left|_left|_right|-R-|-L-|l$|r$|l |r |\\(.*\\))','', name)) for (skid, name) in names.items()])\n",
    "# map name to type \n",
    "nametotype = dict([(names_noside[skid], thistype) for skid, thistype in types.items()])\n",
    "nametotype_add = dict([(names_noside[skid], thistype) for skid, thistype in types_add.items() if skid != 'no pair'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9614e2f9-96a9-435f-afbc-188d50af49c2",
   "metadata": {},
   "source": [
    "# get connectome from catmaid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e37a48d5-3495-433d-ae9e-cb26b1418b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymaid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f47106-9072-4f7c-9fff-1d43b7da9339",
   "metadata": {},
   "outputs": [],
   "source": [
    "rm = pymaid.connect_catmaid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6350e54-3dc8-4466-80d0-1729911e48e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "allns = pymaid.find_neurons(annotations = ['Berck, Khandelwal et al. 2016', \n",
    "                      'Eschbach, Fushiki et al. 2020', \n",
    "                      'Eschbach, Fushiki et al. 2020b', \n",
    "                      'Hueckesfeld et al. 2020', \n",
    "                      'Larderet, Fritsch et al. 2017', \n",
    "                      'Miroschnikow et al. 2018', \n",
    "                      'Schlegel et al. 2016', \n",
    "                      'Tastekin et al. 2018', \n",
    "                      'Winding, Pedigo et al. 2023'])\n",
    "allns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f5f037f-4b61-470e-b750-a206f2a0a12d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many are neurons? \n",
    "unique, counts = np.unique(allns.type, return_counts=True)\n",
    "dict(zip(unique,counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d3e630-8c91-4da2-8ffc-e4efd139e388",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this seems to get all the sensory neurons, better than the annotation 'mw sens'\n",
    "# the difference seem to be in the VNC \n",
    "anton_sensory = pymaid.find_neurons(annotations = ['all sensory neurons'])\n",
    "anton_sensory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa4c031-cadb-4db0-bee7-622cceba8130",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update names \n",
    "names = {**dict(zip(allns.skeleton_id, allns.name)), **dict(zip(anton_sensory.skeleton_id, anton_sensory.name))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6317a8d-48c6-42fb-b6cf-88be74df74b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "adj = pymaid.adjacency_matrix(list(names.keys()))\n",
    "adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59fb7be3-5eec-4d3f-af22-421552d2f482",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the ones without any postsynapses \n",
    "# if you remove these neurons, you remove their presynapses as well. So then you have some new neurons without any postsynapses (without receiving info from anyone)\n",
    "adj = adj.loc[adj.sum() > 0.5,adj.sum() > 0.5]\n",
    "inprop = adj.div(adj.sum(), axis = 'columns')\n",
    "u, counts = np.unique(inprop.sum(), return_counts=True)\n",
    "dict(zip(u, counts))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "790e02e0-6bf2-4461-b06b-ee92362c4875",
   "metadata": {},
   "source": [
    "Note that this is no longer axo-dendritic. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc5d0cf7-0215-48b1-98c0-ce563a4ff13e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "notinWP = [names[skid] for skid in names.keys() if skid not in types]\n",
    "notinWP.sort()\n",
    "notinWP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39181f6c-2055-4155-9763-1468a35c001d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update types\n",
    "types = {**types, **dict.fromkeys(anton_sensory.skeleton_id, 'sensory')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6295ff25-7d81-4ede-a2f5-8a9bb0a35e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "lefts = pymaid.find_neurons(annotations = ['mw left'])\n",
    "rights = pymaid.find_neurons(annotations = ['mw right'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c74bde4-531d-4881-b268-aa7191d6ccb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "lefts_notpublished = lefts[[skid not in types.keys() for skid in lefts.skeleton_id]]\n",
    "rights_notpublished = rights[[skid not in types.keys() for skid in rights.skeleton_id]]\n",
    "rights_notpublished"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da91e659-cde8-4a92-b151-62f8839fc90a",
   "metadata": {},
   "source": [
    "# matrix multiplications"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28df69af-e1f0-434c-ab16-33a49b7b41aa",
   "metadata": {
    "tags": []
   },
   "source": [
    "## try a few multiplications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f55a0ef6-f378-468c-a32f-5f7ba4cc7154",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # @ is matrix multiplicaiton \n",
    "# once = ini @ ad_inprop\n",
    "# # within one step, what's the proportion of input accounted for? \n",
    "# once.stack().plot.hist(bins = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5702070-215a-4eb1-8164-5173cd4035ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# once.stack().plot.hist(bins = [0.0001,0.0005,0.001,0.002,0.005,0.1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ae33dd-c231-4af8-b914-61968cf7ce36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# twice = ini @ ad_inprop @ ad_inprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116c3091-136f-4811-be62-c9d099b76cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# twice.stack().plot.hist(bins = [0.0001,0.0005,0.001,0.002,0.005,0.1,0.2,0.5,0.8,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc45e50-057c-4a18-817f-99954a5de85d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # same as ini @ ad_inprop @ ad_inprop\n",
    "# ini@np.linalg.matrix_power(ad_inprop, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d56220c-df1e-4086-a380-15d5884c8948",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # cumulative plot \n",
    "# data = twice.stack().values\n",
    "# data_sorted = np.sort(data)\n",
    "# p = 1. * np.arange(len(data)) / (len(data) - 1)\n",
    "\n",
    "# plt.plot(data_sorted,p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "581efa76-a7d6-4a11-be27-960dac2bedc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # have a look at the biggest values \n",
    "# data_sorted[-100:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea98406-88cb-4c56-a40a-9633fb397e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sum([datum == 0 for datum in data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ad420e-8753-4064-a709-80f543161af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # how many values in total? \n",
    "# twice.shape[0]**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a6cf26a-afef-4c56-b8da-8d894f356ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8638448/8714304"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c3f4e0e-5177-4b74-affb-608067d8af3b",
   "metadata": {},
   "source": [
    "## total input contributed by senses \n",
    "At different steps "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01382435-9d77-4072-a790-0f22a611f2a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a function that takes in skids as starting points, and calculate the amount of input contributed by those skids, for n steps \n",
    "def generate_steps(skids, ad_inprop, step_number, threshold=0): \n",
    "    # create the inital almost-identity matrix \n",
    "    ini = ad_inprop.copy()\n",
    "    # turn all values to 0, then assign 1 to the sensory ones on the diagonal \n",
    "    for col in ini.columns:\n",
    "        ini[col].values[:] = 0\n",
    "        if col in skids:\n",
    "            ini.loc[col,col] = 1\n",
    "    \n",
    "    steps_fast = []\n",
    "    for i in range(step_number): \n",
    "        # e.g. if step_number is 2, then range(step_number) is [0,1] \n",
    "        # the if i==0 block gives 'how many neurons receive direct* input from skids, as shown in the connectome' \n",
    "        # then the i=1 step gives 'how many neurons receive input from skids, with one neuron in the middle' \n",
    "        if i==0: \n",
    "            # the first step of signal propagation \n",
    "            unthresholded = ini@np.linalg.matrix_power(ad_inprop, 1)\n",
    "            steps_fast.append(unthresholded.where(unthresholded>=threshold, 0))\n",
    "            steps_fast[-1].columns = steps_fast[-1].index.copy()\n",
    "        else: \n",
    "            # multiply the last result  with ad_inprop \n",
    "            unthresholded = steps_fast[-1]@ad_inprop\n",
    "            steps_fast.append(unthresholded.where(unthresholded>=threshold, 0))\n",
    "    \n",
    "    return steps_fast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed38b44-9c47-4509-bc9d-db2d4be6e987",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "step_number = 15\n",
    "selectin = [skid for skid in ad_inprop.columns if types[skid] == 'sensory']\n",
    "steps = generate_steps(selectin, ad_inprop, step_number)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e63a1b2-bce5-4a5a-ac78-8a2a72563623",
   "metadata": {},
   "source": [
    "The cell above gives the same results as: \n",
    "```\n",
    "steps = []\n",
    "for i in range(stepnum): \n",
    "    steps.append(ini@np.linalg.matrix_power(ad_inprop, i+1))\n",
    "but if you did print(np.array_equal(steps[i].values, steps_fast[i].values)), it'll tell you they are not the same \n",
    "this is because Python struggles a bit with very small or very large numbers. In your case very small numbers. \n",
    "you can check this by the following code: \n",
    "\n",
    "for i in range(stepnum): \n",
    "    #print(np.array_equal(steps[i].values, steps_fast[i].values))\n",
    "    print(np.allclose(steps[i].values, steps_fast[i].values))\n",
    "\n",
    "    print(np.max(np.abs(steps[i].values-steps_fast[i].values)))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b62a6c-12ca-47e2-98b6-78281643f472",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# sum the first n steps \n",
    "def add_steps(steps, n): \n",
    "    # n must be 1 or larger \n",
    "    m = steps[0].copy()\n",
    "    # the first step of signal propagation \n",
    "    if n==1: \n",
    "        return m\n",
    "    else: \n",
    "        for i in range(n-1): \n",
    "            m = m + steps[i+1]\n",
    "        return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ec1ad9-8826-46cd-bad6-738808186c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check a few \n",
    "add_steps(steps, 2).sum(axis = 'rows').hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c37feb-2fb5-4057-a5d3-e11e2bf688dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_steps(steps, 8).sum(axis = 'rows').hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa2fd5c-30e4-49db-9a71-47c262e4bd06",
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_thresholded = generate_steps(selectin, ad_inprop, step_number, 0.001)\n",
    "add_steps(steps_thresholded, 14).sum(axis = 'rows').hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67152e6d-2117-457c-9822-de13a5aae5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_steps(steps, 14).sum(axis = 'rows').hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "660a1214-f481-41af-aaa7-c99011b92bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we should exclude the sensory neurons in the columns, and non-sensory neurons in the rows (since the values are 0 anyway) \n",
    "not_sensory = [idx not in selectin for idx in steps[0].index]\n",
    "sensory = [idx in selectin for idx in steps[0].index]\n",
    "steps_nosense = []\n",
    "# choose thresholded or not \n",
    "for m in steps: \n",
    "    m.columns = m.index\n",
    "    steps_nosense.append(m.loc[sensory,not_sensory])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c02d0418-5fba-48ef-a608-785b2ae2a5ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_nosense[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dffe0e0-7142-498f-8c68-1a94828dc5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_steps(steps_nosense, 3).sum(axis = 'rows').hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff8d661-6a7b-48eb-814d-54342f13856e",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_steps(steps_nosense, 8).sum(axis = 'rows').hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac93961-0cc5-44de-b90b-98ce12cc5074",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_steps(steps_nosense, 14).sum(axis = 'rows').hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e222e82-28fc-4575-9b39-c1dbd358abdb",
   "metadata": {
    "tags": []
   },
   "source": [
    "## histograms of contributions of different steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66633211-c208-452b-ba48-81bd4c20f95e",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 14\n",
    "stepsn = add_steps(steps_nosense, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd86e25-617b-4105-bf01-305df1f73981",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sum across multiple input sensory neurons, and take the average of the postsynaptic neurons \n",
    "stepsn_noside = stepsn.groupby(names_noside).sum().groupby(names_noside, axis = 1).mean()\n",
    "stepsn_noside"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "305f190d-60e9-4952-9871-8f7764af3e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sensein_step = []\n",
    "for i in range(len(steps_nosense)): \n",
    "    # how much input accounted for at each step for each neuron? \n",
    "    sensein_step.append(steps_nosense[i].sum(axis='rows'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb9c631-73e5-4c79-8283-dfbb1e5e09c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "palette = sns.color_palette(\"Spectral\", len(sensein_step))\n",
    "plt.hist(sensein_step, stacked=True, bins = 20, color = palette)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ea65a8-f14d-4e18-a987-c4cb2b8b8cd0",
   "metadata": {},
   "source": [
    "This shows that all the steps make similar contributions to neurons' inputs: very few neuron has much of their input accounted for by the first step or two (the low y values where x values are high). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd8cba1-f6e1-47ba-9d09-498fba631fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "palette"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd512977-b72d-4cf3-b4bd-cc424c05b13a",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(steps_nosense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdef5ce5-0b27-4a79-b37d-df27f135a909",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sum up all the steps \n",
    "sensein_sum = []\n",
    "for i in range(len(steps_nosense)): \n",
    "    sensein_sum.append(add_steps(steps_nosense, i+1).sum(axis = 'rows'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db260b18-f7ac-4c84-9ddc-dcc693588aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(sensein_sum, stacked=True, bins = 20, color = palette, bottom=0, alpha = 0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aef9c05e-b294-46b2-9f51-5f365907f04e",
   "metadata": {},
   "source": [
    "On the right of the plot above, you can see that there are neurons that have nearly 100% of their input accounted for by the last step (the neurons in the last bar) (though some of them got there earlier than others). \n",
    "The bar on the left is explained by neurons that have little input from the senses in the first few steps. The blue top means that there are a few neurons which don't have a lot of their input accounted for by the senses, even at the end of the steps. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f43d0b62-87c7-455a-84c0-1b423f95247a",
   "metadata": {},
   "source": [
    "## cumulative plot per neuron"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d6932fb-30ee-4fb0-9c8a-9833a4b6d0e5",
   "metadata": {},
   "source": [
    "First get the percentage input accounted for for each neuron at the end of stepping. Then take an average per type. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39380113-92a1-48bb-bef7-e731e7c451b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_sensein_pertype = {}\n",
    "sensein_pertype = {}\n",
    "for atype in set(types.values()): \n",
    "    if atype == 'sensory': \n",
    "        continue \n",
    "    # amount of input accounted for by the senses, for this cell type \n",
    "    sensein_pertype[atype] = [sensein_sum[-1][skid] for skid in sensein_sum[-1].index \n",
    "                              if types[skid] == atype]\n",
    "    # calculate mean for this cell type\n",
    "    mean_sensein_pertype[atype] = sum(sensein_pertype[atype]) / len(sensein_pertype[atype])\n",
    "mean_sensein_pertype = pd.DataFrame.from_dict(mean_sensein_pertype, \n",
    "                                              orient='index', \n",
    "                                              columns=['Value']).sort_values('Value')\n",
    "mean_sensein_pertype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea828a7-2856-4694-8bb1-a7abb5113ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a dictionary of cell types and colours \n",
    "typecolourdict = dict(zip(mean_sensein_pertype.index, \n",
    "                          sns.color_palette(\"Spectral\", len(set(types.values()))).as_hex()))\n",
    "# turn MBIN to black so that it's easier to see \n",
    "typecolourdict['MBIN'] = '#0d0d0d'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e7ddf7-e6d3-40f6-940f-c4fcbaec58b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save colour mapping for other scripts \n",
    "pd.DataFrame(typecolourdict.items(), columns=['type_name', 'colour']).to_csv('/Users/yijieyin/Downloads/larva/type_colour_dict.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feeba5f3-e451-4700-8a47-b5d9d97eb3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# have a look at the colours\n",
    "sns.color_palette(\"Spectral\", len(set(types.values())))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a5f573-f5c0-4390-b047-29d653beb05e",
   "metadata": {},
   "source": [
    "Red: very little input accounted for by senses;  \n",
    "Blue: a lot of input accounted for by the senses. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df10ea5c-b1fd-4e56-9ec7-dadacd22c92e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (15,10))\n",
    "plt.hist(sensein_pertype.values(), stacked=True, bins = 20, label=list(sensein_pertype.keys()), \n",
    "        color=[typecolourdict.get(key) for key in sensein_pertype.keys()],\n",
    "        orientation='horizontal')\n",
    "plt.ylabel(\"Input proportion accounted for by the senses in paths <= \" + str(n) + ' hops')\n",
    "plt.xlabel(\"Number of neurons\")\n",
    "plt.legend()\n",
    "plt.title('Input proportion accounted for by senses for each cell class')\n",
    "if savefig: \n",
    "    plt.savefig('/Users/yijieyin/Desktop/conferences/PDN_symposium/inprop_bysenses.pdf', bbox_inches='tight')\n",
    "else: \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc3a0096-762a-4a43-9019-e48658c3d31f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (15,10))\n",
    "for skid in sensein_sum[0].index: \n",
    "    xs = [i+1 for i in range(len(sensein_sum))]\n",
    "    ys = [onesenseinsum[skid] for onesenseinsum in sensein_sum]\n",
    "    \n",
    "    plt.plot(xs, ys, alpha = 0.5, color = typecolourdict[types[skid]]) \n",
    "\n",
    "plt.xlabel('Number of hops from the senses')\n",
    "plt.ylabel('Input proportion accounted for by the senses')\n",
    "plt.title('Cumulative input proportion accounted for by the senses')\n",
    "if savefig: \n",
    "    plt.savefig('/Users/yijieyin/Desktop/conferences/PDN_symposium/inprop_bysenses_stepwise.pdf', bbox_inches='tight')\n",
    "else: \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4f12d8-8edd-4a67-a582-b9d2c0e76545",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "filtered_dict = {k: v for k, v in types.items() if v != 'sensory'}\n",
    "\n",
    "# Count the occurrences of values in the dictionary\n",
    "value_counts = Counter(filtered_dict.values())\n",
    "\n",
    "# Extract the labels and their counts\n",
    "labels, counts = zip(*value_counts.items())\n",
    "# Sort the labels, counts, and colors based on counts (in descending order)\n",
    "sorted_indices = sorted(range(len(counts)), key=lambda i: counts[i], reverse=True)\n",
    "sorted_counts = [counts[i] for i in sorted_indices]\n",
    "sorted_labels = [labels[i] for i in sorted_indices]\n",
    "colors = [typecolourdict[label] for label in sorted_labels]\n",
    "\n",
    "# Create a pie plot\n",
    "fig, ax = plt.subplots(figsize = (15,10))\n",
    "ax.pie(sorted_counts, labels=sorted_labels, \n",
    "       autopct=\"%1.1f%%\", startangle=90, \n",
    "       colors = colors, \n",
    "#       wedgeprops=dict(width=0.4, edgecolor=\"w\", linewidth=2), \n",
    "      textprops=dict(size=10))\n",
    "ax.axis(\"equal\")  # Ensure the pie chart is a circle\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a044d9f-a362-4629-9af7-fd5f5112e057",
   "metadata": {},
   "source": [
    "### select a cell type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb4d8f84-4c07-4ff7-805a-e377c066b353",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check a particular cell type \n",
    "skids = [skid for skid in sensein_sum[0].index if types[skid]=='MBIN' and 'DAN' in types_add[skid]]\n",
    "\n",
    "celltypes = set([types_add[skid] for skid in skids])\n",
    "col_typeadd = dict(zip(sorted(celltypes), \n",
    "                       sns.color_palette(\"hls\",len(celltypes)).as_hex()))\n",
    "# Set line style based on 'sides' dictionary\n",
    "line_styles = {'left': '-', 'right': '--'}\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15, 10))\n",
    "for skid in skids: \n",
    "    xs = [i+1 for i in range(len(sensein_sum))]\n",
    "    ys = [onesenseinsum[skid] for onesenseinsum in sensein_sum]\n",
    "    \n",
    "    plt.plot(xs, ys, \n",
    "             color=col_typeadd[types_add[skid]], linestyle=line_styles[sides[skid]], \n",
    "             label=f\"{types_add[skid]} ({sides[skid]})\", \n",
    "            lw = 3)\n",
    "\n",
    "plt.xlabel('Steps from the senses')\n",
    "plt.ylabel('Input proportion accounted for by the senses')\n",
    "\n",
    "# Create legends\n",
    "# Legend for colors\n",
    "color_patches = [mpatches.Patch(color=color, label=celltype) for celltype, color in col_typeadd.items()]\n",
    "color_legend = plt.legend(handles=color_patches, loc='lower right', bbox_to_anchor=(1, 0.15),\n",
    "                          title='Cell Types')\n",
    "\n",
    "# Add the color_legend back to the plot so it doesn't get overwritten by the next legend\n",
    "plt.gca().add_artist(color_legend)\n",
    "\n",
    "# Legend for sides\n",
    "side_lines = [mlines.Line2D([], [], color='black', label=side, linestyle=line_styles[side], linewidth=2) for side in set(sides.values())]\n",
    "plt.legend(handles=side_lines, loc='lower right', \n",
    "           title='Sides')\n",
    "plt.title(\"What about Dopaminergic neurons?\")\n",
    "if savefig: \n",
    "    plt.savefig('/Users/yijieyin/Desktop/conferences/PDN_symposium/inprop_bysenses_stepwise_DANj.pdf', bbox_inches='tight')\n",
    "else: \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1247cd31-d134-40ba-8ca9-b1acdea6d293",
   "metadata": {},
   "source": [
    "But what does that mean? \n",
    "which senses? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab2362cc-d5a6-45ac-a5ea-0eb360ad262a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# then print the numbers for each cell type \n",
    "# check a particular cell type \n",
    "skids = [skid for skid in sensein_sum[0].index if types[skid]=='MBIN' and 'DAN' in types_add[skid]]\n",
    "\n",
    "for skid in skids: \n",
    "    xs = [i+1 for i in range(len(sensein_sum))]\n",
    "    ys = [round(onesenseinsum[skid], 4) for onesenseinsum in sensein_sum]\n",
    "    print(types_add[skid])\n",
    "    print(ys)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f518e73-2ceb-4baf-9cca-93c3de1bd3f3",
   "metadata": {},
   "source": [
    "##Â not cumulative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de67693-00fb-4448-8937-1f3ce84e9cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (15,10))\n",
    "# for all non-sensories \n",
    "for skid in tqdm(sensein_sum[0].index): \n",
    "    if types[skid] == 'sensory': \n",
    "        continue\n",
    "    xs = [i+1 for i in range(len(sensein_step))]\n",
    "    ys = [onestep[skid] for onestep in sensein_step]\n",
    "    \n",
    "    plt.plot(xs, ys, alpha = 0.5, color = typecolourdict[types[skid]]) \n",
    "\n",
    "plt.xlabel('Number of hops from the senses')\n",
    "plt.ylabel('Input proportion accounted for by the senses')\n",
    "plt.title('Input proportion accounted for by the senses')\n",
    "if savefig: \n",
    "    plt.savefig('/Users/yijieyin/Desktop/conferences/PDN_symposium/inprop_bysenses_stepwise_not_cumulative.pdf', bbox_inches='tight')\n",
    "else: \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c9a482a-f57a-427d-b7ba-d11cbd5e1a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "unstacked_df = stepsn.unstack().reset_index(drop=True)\n",
    "\n",
    "# Set up the figure\n",
    "fig, ax = plt.subplots(figsize = (15,10))\n",
    "\n",
    "# Plot the histogram with log scale for both x and y axes\n",
    "ax.hist(unstacked_df, bins=np.logspace(-3, 0, 40))\n",
    "ax.set_xscale('log')\n",
    "ax.set_yscale('log')\n",
    "\n",
    "# Set labels and title\n",
    "ax.set_xlabel('Strength of connection (Log Scale)')\n",
    "ax.set_ylabel('Number of connections (Log Scale)')\n",
    "ax.set_title('Number of connections vs. strength of connection')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea1c258-4c45-4a67-91c7-389657887c14",
   "metadata": {
    "tags": []
   },
   "source": [
    "# DAN's input from senses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a00ca916-04c4-4daa-b169-8de8fdbea814",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sum the input proportion by sensory type \n",
    "sensesn = stepsn.groupby(by = [types_add[idx] for idx in stepsn.index]).sum()\n",
    "sensesn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6204f97-69a2-4e64-aa90-11dde8cb559e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# sanity check that it's the right axes \n",
    "sensesn.sum(axis = 'rows').hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "862ec814-286f-4813-a4e2-177bc02db64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's take a look at the dans \n",
    "dans_sensein = sensesn.loc[:,[types[skid] == 'MBIN' for skid in sensesn.columns]].T\n",
    "dans_sensein['cell_type'] = [types_add[skid] for skid in dans_sensein.index]\n",
    "dans_sensein['side'] = [sides[skid] for skid in dans_sensein.index]\n",
    "dans_sensein.sort_values('cell_type').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e9fa0a-d49b-416d-a774-ebcb9c08decb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # round and write to clipboard \n",
    "# dans_sensein.sort_values('cell_type').round(4).to_clipboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5577c824-1899-4196-a4ce-5890131c7d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "vmin = dans_sensein.drop(['cell_type','side'], axis = 1).min().min()\n",
    "vmax = dans_sensein.drop(['cell_type','side'], axis = 1).max().max()\n",
    "\n",
    "dans_sensein_dp = dans_sensein.sort_values('cell_type').style.background_gradient(cmap='Blues', vmin = vmin, vmax = vmax)\n",
    "display(dans_sensein_dp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ecb5c04-f6a6-44dd-bcca-d4a79c20ebbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # line plot \n",
    "# strictly_dan_sensein = dans_sensein[['DAN' in thistype for thistype in dans_sensein.cell_type]]\n",
    "\n",
    "# fig, ax = plt.subplots(figsize=(15, 10))\n",
    "# sensory_columns = strictly_dan_sensein.columns[:-2]\n",
    "\n",
    "# for idx, row in strictly_dan_sensein.iterrows():\n",
    "#     plt.plot(sensory_columns, row[sensory_columns], \n",
    "#              color=col_typeadd[row['cell_type']], linestyle=line_styles[row['side']], \n",
    "#              label=f\"{row['cell_type']} ({row['side']})\", \n",
    "#             lw = 3)\n",
    "\n",
    "# # plt.xlabel('Sensory modality')\n",
    "# plt.ylabel('Contribution')\n",
    "# plt.xticks(np.arange(len(sensory_columns)), sensory_columns, rotation=30)\n",
    "\n",
    "# # don't actually need these because legends are covered in the previous plots \n",
    "# # # Create legends\n",
    "# # # Legend for cell types\n",
    "# # color_patches = [mpatches.Patch(color=color, label=celltype) for celltype, color in col_typeadd.items()]\n",
    "# # color_legend = plt.legend(handles=color_patches, bbox_to_anchor=(1, 1), loc='upper right', title='Cell Types')\n",
    "\n",
    "# # # Add the color_legend back to the plot so it doesn't get overwritten by the next legend\n",
    "# # plt.gca().add_artist(color_legend)\n",
    "\n",
    "# # # Legend for sides\n",
    "# # side_lines = [mlines.Line2D([], [], color='black', label=side, linestyle=line_styles[side], linewidth=2) for side in set(strictly_dan_sensein['side'])]\n",
    "# # plt.legend(handles=side_lines, bbox_to_anchor=(1, 0.4), loc='upper right', title='Sides')\n",
    "\n",
    "# plt.title('How much from which senses?')\n",
    "\n",
    "# # plt.show()\n",
    "# plt.savefig('/Users/yijieyin/Desktop/conferences/PDN_symposium/inprop_bysenses_DANj.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "025e5aa9-1f04-4709-95fb-58caba8b0dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scatter plot \n",
    "strictly_dan_sensein = dans_sensein[['DAN' in thistype for thistype in dans_sensein.cell_type]]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15, 10))\n",
    "sensory_columns = strictly_dan_sensein.columns[:-2]\n",
    "\n",
    "x_values = np.arange(len(sensory_columns))\n",
    "\n",
    "for idx, row in strictly_dan_sensein.iterrows():\n",
    "    plt.scatter(x_values, row[sensory_columns],\n",
    "                color=col_typeadd[row['cell_type']],\n",
    "                label=f\"{row['cell_type']} ({row['side']})\",\n",
    "                s=50)  # Set the marker size with the s parameter, adjust as needed\n",
    "\n",
    "plt.ylabel('Contribution')\n",
    "plt.xticks(x_values, sensory_columns, rotation=30)\n",
    "plt.title('How much from which senses?')\n",
    "\n",
    "if savefig: \n",
    "    plt.savefig('/Users/yijieyin/Desktop/conferences/PDN_symposium/inprop_bysenses_DANj.pdf', bbox_inches='tight')\n",
    "else: \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4261419-3b5f-4fd0-8f50-c196607e7ca5",
   "metadata": {},
   "source": [
    "## deeper = flatter? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0497706a-a99d-48bc-93f5-f1ce032586f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "variance = sensesn.var(axis = 0)\n",
    "depth = sensesn.sum(axis = 0)\n",
    "fig, ax = plt.subplots(figsize=(15, 10))\n",
    "plt.scatter(depth, variance, color = [typecolourdict[types[skid]] for skid in sensesn.columns])\n",
    "plt.xlabel('Input proportion accounted for') \n",
    "plt.ylabel('Variance') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7809e4b5-50f9-461c-b8e5-c6b9d69922a3",
   "metadata": {},
   "source": [
    "The bleu ones (PNs and KCs) have biased inputs. For the red-ish ones (e.g. AN, PN-somato, DN-VNC), it does seem like: the more input accounted for, the more biased the input - but perhaps this is an artefact of values being larger? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e486dc2b-4ed1-4a74-bfdb-3e298f65c45b",
   "metadata": {},
   "source": [
    "**Gini coefficient**: The Gini coefficient is a measure of inequality, originally developed for income distribution in economics, but it can also be applied to your vector. A Gini coefficient of 0 represents perfect equality (a \"flat\" vector), and a Gini coefficient of 1 represents maximum inequality (a \"skewed\" vector).  \n",
    "\n",
    "$$\\frac{\\sum((2 \\cdot \\text{{index}} - n - 1) \\cdot \\text{{vector}})}{n \\cdot \\sum(\\text{{vector}})}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb98fab-b12d-4981-892b-97992dad5300",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gini(vector):\n",
    "    vector = np.array(vector)\n",
    "    vector = np.sort(vector)  # values must be sorted\n",
    "    index = np.arange(1, vector.shape[0] + 1)  # index per data point\n",
    "    n = vector.shape[0]  # number of data points\n",
    "    return ((np.sum((2 * index - n  - 1) * vector)) / (n * np.sum(vector)))  # Gini coefficient\n",
    "\n",
    "flat_vector = [0.2, 0.2, 0.2, 0.2, 0.2]\n",
    "skewed_vector = [1, 0, 0, 0, 0]\n",
    "\n",
    "print(gini(flat_vector))  # prints a low number\n",
    "print(gini(skewed_vector))  # prints a high number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67564ad6-d309-4139-8332-c43905eeb349",
   "metadata": {},
   "outputs": [],
   "source": [
    "ginico = sensesn.apply(gini, axis = 0).fillna(0)\n",
    "ginico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745a9327-fdff-4bbf-8510-070b77b13d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15, 10))\n",
    "plt.scatter(depth, ginico, color = [typecolourdict[types[skid]] for skid in sensesn.columns])\n",
    "plt.xlabel('Input proportion accounted for') \n",
    "plt.ylabel('Gini coefficient') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67fe1a77-8275-43b5-a6c0-4f714de5e2b8",
   "metadata": {},
   "source": [
    "Okay. So all are okay except for PNs and KCs which take very biased input. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb48c01-fc65-47d9-8ea1-6999d24e3edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# question: this is annotated 'mechanosensory', but why is it gustatory here? \n",
    "types_add['16362243']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a4c9ed-f111-4cc3-9339-621e4ebc97c6",
   "metadata": {},
   "source": [
    "**Albert on 20/March/2023:**  \n",
    "The PAM cluster: DAN-ijk and h (h is not there in L1) are involved in reward learning  \n",
    "DAN activity: signal good things  \n",
    "enteric must be good-sensing?  \n",
    "\n",
    "There are 2 sugar sensors that are unsusal: they ascend and cross the midline.  \n",
    "if you load all the sensories, two ascend in the brain, and they should be in the sensory category, instead of ascending. \n",
    "If we hypothesise that DANj1 is looking for positive signal:  \n",
    "20% of the olfactory input for DANj1: they should be alcohol related  \n",
    "\n",
    "The ORNs stay close-by in the antennal lobe based on valence:  \n",
    "    medial: things larva like  \n",
    "    lateral: doesn't like  \n",
    "\n",
    "nutrition values isn't by taste  \n",
    "e.g. L-sugar tastes sweet, but no nutrition value  \n",
    "DANj is people's favourite  \n",
    "DANj not reading much from visual: visual is mostly negative in the larva  \n",
    "respiratory: O2 measurement: so it's positive  \n",
    "\n",
    "DANc1 is mysterious: it's in the PED, no one knows what they do \n",
    "\n",
    "warm sensors: 2 cells go to broad LNs in the AL: normalisation by temperature  \n",
    "those neurons must go to the mPNs, then some mPNs must go to DANs, so there should be input from warm sensors to DANs    \n",
    "DANj1 is receiving slightly more from warm than cold.  \n",
    "\n",
    "cold sensors: synapse onto 3-5 PNs, no LNs, straight to the brain.  \n",
    "2-5% input of the DANs  \n",
    "\n",
    "MBIN-e: it's in the e compartment lobe.  \n",
    "\n",
    "some senses are entirely positive/negative: \n",
    "e.g. respiratory measures O2, and O2 is always good  \n",
    "sensing of heat and cold ramps: [Louis Hermandez Nunez, Cardona, Samuel et al.](https://pubmed.ncbi.nlm.nih.gov/34452914/)  \n",
    "warm cells: broad LNs: normalise for temperature  \n",
    "there are also warming PNs: then I-PNs converge from cold and warm  \n",
    "\n",
    "[Diversity of Internal Sensory Neuron Axon Projection Patterns Is Controlled by the POU-Domain Protein Pdm3 in Drosophila Larvae](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5824742/)   \n",
    "They are in the trachea: axons to the abdominal segments, then anterial with the dorsolateral tract: when they reach a1 segment, then go medially and go into the brain  \n",
    "    tracheal sensory neurons that go to the brain  \n",
    "    brain receive direct input from O2  \n",
    "DANj1: reads the most from that?  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e512f1a-242f-4b9c-9fd4-6ee1124d6e47",
   "metadata": {
    "tags": []
   },
   "source": [
    "# dimensionality reduction by senses "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c50c0c5-aaf0-4945-84c9-427f5fc4f9ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a68838-b9df-4cff-8038-5870337a3166",
   "metadata": {},
   "outputs": [],
   "source": [
    "sensesn.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "340af909-8682-43a7-bd6d-2f4fe53d9a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA()\n",
    "x = sensesn.T\n",
    "x_pca = pca.fit_transform(x)\n",
    "x_pca = pd.DataFrame(x_pca)\n",
    "x_pca.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c859065-31df-4d95-bcdb-19411d5084bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0301eed-7581-4bb4-aff0-8baae975ac37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the following line to add colours in the future \n",
    "# x_pca[âtargetâ]=y\n",
    "x_pca.columns = ['PC{}'.format(n) for n in range(x_pca.shape[1])]\n",
    "x_pca.index = x.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28df561e-3310-4eb7-90b6-2d7ed050716c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(1,1,1) \n",
    "ax.set_xlabel('Principal Component 1') \n",
    "ax.set_ylabel('Principal Component 2') \n",
    "ax.set_title('2 component PCA') \n",
    "# targets = [âIris-setosaâ, âIris-versicolorâ, âIris-virginicaâ]\n",
    "# colors = [ârâ, âgâ, âbâ]\n",
    "# for target, color in zip(targets,colors):\n",
    "#  indicesToKeep = x_pca[âtargetâ] == target\n",
    "#  ax.scatter(x_pca.loc[indicesToKeep, âPC1â]\n",
    "#  , x_pca.loc[indicesToKeep, âPC2â]\n",
    "#  , c = color\n",
    "#  , s = 50)\n",
    "# ax.legend(targets)\n",
    "\n",
    "ax.scatter(x_pca.PC0, x_pca.PC1)\n",
    "ax.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e9216d9-5a17-4e75-a762-cd71509f45c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check some cell types based on the plot above \n",
    "criteria = [x_pca.loc[i,'PC2']>0.6 for i in x_pca.index]\n",
    "for i, j in zip([types[key] for key in x.index[criteria]], [types_add[key] for key in x.index[criteria]]): \n",
    "    print('{}: {}'.format(i,j))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3814e1e2-f5d1-42da-8461-1ccffdfddd41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check some additional cell types\n",
    "criteria = [x_pca.loc[i,'PC1']<-0.2 and x_pca.loc[i,'PC2']<-0.4 for i in x_pca.index]\n",
    "# both PC1 and PC2 at the bottom left corner \n",
    "for i, j in zip([types[key] for key in x.index[criteria]], [types_add[key] for key in x.index[criteria]]): \n",
    "    print('{}: {}'.format(i,j))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c2875f2-919b-4291-a1f8-9047dd55354a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# which kind of PNs are there? \n",
    "meta[meta.celltype == 'PN'].annotated_name.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50b28e45-1835-4099-b9d1-a1e92ad808dd",
   "metadata": {},
   "source": [
    "## colouring PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d59fe4d-e5d5-44a4-8884-675003fbb534",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select specific cell types to colour \n",
    "x_pca['cell_type']= [types[idx] for idx in x_pca.index]\n",
    "\n",
    "fig = plt.figure(figsize=(15,10))\n",
    "ax = fig.add_subplot(1,1,1) \n",
    "ax.set_xlabel('Principal Component 1') \n",
    "ax.set_ylabel('Principal Component 2') \n",
    "ax.set_title('2 component PCA') \n",
    "\n",
    "for target, color in typecolourdict.items():\n",
    " indicesToKeep = x_pca['cell_type'] == target\n",
    " ax.scatter(x_pca.loc[indicesToKeep, 'PC0']\n",
    " , x_pca.loc[indicesToKeep, 'PC1']\n",
    " , c = color\n",
    " , s = 50, alpha = 0.5, \n",
    "           label = target)\n",
    "ax.legend()\n",
    "ax.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7838eabe-4b55-4946-ab2f-c8fb176721a4",
   "metadata": {},
   "source": [
    "### interactive PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72059e46-839d-47d8-90cb-051712ff4355",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA()\n",
    "x = sensesn.T\n",
    "x_pca = pca.fit_transform(x)\n",
    "x_pca = pd.DataFrame(x_pca)\n",
    "x_pca.columns = ['PC{}'.format(n) for n in range(x_pca.shape[1])]\n",
    "x_pca.index = x.index\n",
    "x_pca['type_name'] = [types[skid] for skid in x_pca.index]\n",
    "x_pca['colour'] = [typecolourdict[atype] for atype in x_pca.type_name]\n",
    "x_pca['side'] = [sides[skid] for skid in x_pca.index]\n",
    "x_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2742c3ca-b328-4cc7-b89a-f2e8e379fdd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Â plotting \n",
    "datasource = ColumnDataSource(x_pca)\n",
    "\n",
    "plot = figure(\n",
    "    title='UMAP projection of individual inputs',\n",
    "    width=1200,\n",
    "#     plot_height=600,\n",
    "    tools=('pan, wheel_zoom, reset')\n",
    ")\n",
    "\n",
    "renderer = plot.circle(\n",
    "    'PC0',\n",
    "    'PC1',\n",
    "    source=datasource,\n",
    "    color='colour',\n",
    "    legend_field = 'type_name',\n",
    "    line_alpha=0.6,\n",
    "    fill_alpha=0.6,\n",
    "    size=4, \n",
    "    selection_alpha=0.8,\n",
    "    nonselection_alpha=0.05\n",
    ")\n",
    "\n",
    "\n",
    "### Create a Select widget for type_name ###\n",
    "type_select = Select(title=\"Select Type:\", \n",
    "                     options=['all'] + list(x_pca['type_name'].unique()), \n",
    "                     value=\"\")\n",
    "\n",
    "side_select = Select(title=\"Select Side:\", \n",
    "                     options=['all'] + list(x_pca['side'].unique()), \n",
    "                     value=\"\")\n",
    "\n",
    "\n",
    "# Define a JavaScript callback function for the widget\n",
    "callback = CustomJS(args=dict(source=datasource, select_type=type_select, select_side=side_select), code=\"\"\"\n",
    "    const selected_type = select_type.value;\n",
    "    const selected_side = select_side.value;\n",
    "    const indices = [];\n",
    "    const data = source.data;\n",
    "    const typeName = data.type_name;\n",
    "    const sideName = data.side;\n",
    "    for (let i = 0; i < typeName.length; i++) {\n",
    "        if ((typeName[i] === selected_type || selected_type === \"all\") &&\n",
    "            (sideName[i] === selected_side || selected_side === \"all\")) {\n",
    "            indices.push(i);\n",
    "        }\n",
    "    }\n",
    "    source.selected.indices = indices;\n",
    "    source.change.emit();\n",
    "\"\"\")\n",
    "\n",
    "# callback = CustomJS(args=dict(source=datasource, select=type_select), code=\"\"\"\n",
    "#     const selected_type = select.value;\n",
    "#     const indices = [];\n",
    "#     const data = source.data;\n",
    "#     const typeName = data.type_name;\n",
    "#     for (let i = 0; i < typeName.length; i++) {\n",
    "#         if (typeName[i] === selected_type || selected_type === \"all\") {\n",
    "#             indices.push(i);\n",
    "#         }\n",
    "#     }\n",
    "#     source.selected.indices = indices;\n",
    "#     source.change.emit();\n",
    "# \"\"\")\n",
    "# Attach the JavaScript callback function to the widget's value change event\n",
    "type_select.js_on_change('value', callback)\n",
    "side_select.js_on_change('value', callback)\n",
    "\n",
    "plot.legend.location = \"top_left\"\n",
    "\n",
    "layout = column(type_select, side_select, plot)\n",
    "\n",
    "# show result\n",
    "show(layout)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10c11367-27dc-4f39-b56d-536bdc2d9c71",
   "metadata": {},
   "source": [
    "## U MAP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "211e67cb-01ef-4d48-baae-be7000d0add5",
   "metadata": {},
   "source": [
    "### sensory modalities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ea8693-10ce-47bc-b28a-1873f47cfe42",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_from_senses = sensesn.T\n",
    "# in_from_senses['type_name'] = in_from_senses.index.map(types)\n",
    "in_from_senses = in_from_senses.groupby(names_noside).mean()\n",
    "in_from_senses['type_name'] = in_from_senses.index.map(nametotype)\n",
    "in_from_senses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e08e54e-08a3-472f-89a9-f454bde4d2ea",
   "metadata": {},
   "source": [
    "#### pair plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe40e51-c1bd-406f-9ba4-cf18ce362276",
   "metadata": {},
   "outputs": [],
   "source": [
    "pairplot_figure = sns.pairplot(in_from_senses, hue = 'type_name')\n",
    "# can't save this for some reason \n",
    "# pairplot_figure.savefig('/Users/yijieyin/Downloads/pair_plot_from_senses.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d60999-c99f-4386-b27d-266d19244018",
   "metadata": {},
   "source": [
    "The more the points are in the middle, the more related the senses are. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e5afa3-aacf-4974-a341-3ba0a04777c8",
   "metadata": {},
   "source": [
    "#### umap\n",
    "\"since the measurements are on entirely different scales it will be helpful to convert each feature into z-scores (number of standard deviations from the mean) for comparability.\" - but our measurements are on the same scale, so no need for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114f02f1-cf00-4e88-a71d-5a969e73d0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install umap-learn\n",
    "import umap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8599955-a7b5-4ac2-ae51-70001fddb61f",
   "metadata": {},
   "outputs": [],
   "source": [
    "reducer = umap.UMAP()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b519a4-e6e5-4e8a-bb68-35a91eeae94d",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_from_senses_data = in_from_senses.drop('type_name', axis = 1).values\n",
    "embedding = reducer.fit_transform(in_from_senses_data)\n",
    "embedding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106556ad-5841-483a-9e2a-31e82ec8ff38",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15,10))\n",
    "plt.scatter(\n",
    "    embedding[:, 0],\n",
    "    embedding[:, 1],\n",
    "    c=[typecolourdict[nametotype[skid]] for skid in in_from_senses.index])\n",
    "plt.gca().set_aspect('equal', 'datalim')\n",
    "plt.title('UMAP projection of input from senses', fontsize=24);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cc236a8-0c14-4ce2-87ca-2f5b88867825",
   "metadata": {},
   "source": [
    "#### interactive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d4d7210-663b-4dcb-857c-552d41ba717d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the data\n",
    "in_from_senses_bk = pd.concat([in_from_senses,\n",
    "           pd.DataFrame(embedding, columns=('x', 'y'), index = in_from_senses.index)], axis = 1)\n",
    "in_from_senses_bk['colour'] = [typecolourdict[atype] for atype in in_from_senses_bk.type_name]\n",
    "in_from_senses_bk['name'] = in_from_senses_bk.index\n",
    "in_from_senses_bk['type_add'] = [nametotype_add[skid] for skid in in_from_senses_bk.index]\n",
    "# change column names because bokeh doesn't like the dashes\n",
    "in_from_senses_bk.rename(columns = {'gustatory-external':'gustatory_external', \n",
    "                                   'gustatory-pharyngeal':'gustatory_pharyngeal', \n",
    "                                   'thermo-cold':'thermo_cold', \n",
    "                                   'thermo-warm':'thermo_warm'}, inplace=True) \n",
    "round_cols = ['gustatory_external','gustatory_pharyngeal','thermo_cold','thermo_warm','enteric','olfactory','respiratory','visual']\n",
    "in_from_senses_bk[round_cols] = in_from_senses_bk[round_cols].round(3)\n",
    "\n",
    "# scale text size by value \n",
    "base = 10\n",
    "scale = 10\n",
    "in_from_senses_bk['olfactory_fontsize'] = in_from_senses_bk['olfactory'].apply(lambda x: str(base+int(x*scale))) # Adjust the scaling factor as needed\n",
    "in_from_senses_bk['enteric_fontsize'] = in_from_senses_bk['enteric'].apply(lambda x: str(base+int(x*scale)))\n",
    "in_from_senses_bk['gustatory_external_fontsize'] = in_from_senses_bk['gustatory_external'].apply(lambda x: str(base+int(x*scale)))\n",
    "in_from_senses_bk['gustatory_pharyngeal_fontsize'] = in_from_senses_bk['gustatory_pharyngeal'].apply(lambda x: str(base+int(x*scale)))\n",
    "in_from_senses_bk['respiratory_fontsize'] = in_from_senses_bk['respiratory'].apply(lambda x: str(base+int(x*scale)))\n",
    "in_from_senses_bk['cold_fontsize'] = in_from_senses_bk['thermo_cold'].apply(lambda x: str(base+int(x*scale)))\n",
    "in_from_senses_bk['warm_fontsize'] = in_from_senses_bk['thermo_warm'].apply(lambda x: str(base+int(x*scale)))\n",
    "in_from_senses_bk['visual_fontsize'] = in_from_senses_bk['visual'].apply(lambda x: str(base+int(x*scale)))\n",
    "in_from_senses_bk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4135c99a-53a7-43c3-82bb-d88875e698ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasource = ColumnDataSource(in_from_senses_bk)\n",
    "\n",
    "plot = figure(\n",
    "    title='UMAP projection of input from senses',\n",
    "    width=800,\n",
    "#     plot_height=600,\n",
    "    tools=('pan, wheel_zoom, reset')\n",
    ")\n",
    "\n",
    "plot.add_tools(HoverTool(tooltips=\"\"\"\n",
    "<div>\n",
    "    <div><span style='font-size: 15px'> @type_name; @name: </span></div>\n",
    "    <div><span style='font-size: @olfactory_fontsize; color: #fc0303'>Olfactory: @olfactory{0.000}</span></div>\n",
    "    <div><span style='font-size: @enteric_fontsize; color: #224499'>Enteric: @enteric{0.000}</span></div>\n",
    "    <div><span style='font-size: @gustatory_external_fontsize; color: #fca103'>Gustatory external: @gustatory_external{0.000}</span></div>\n",
    "    <div><span style='font-size: @gustatory_pharyngeal_fontsize; color: #f8fc03'>Gustatory_pharyngeal: @gustatory_pharyngeal</span></div>\n",
    "    <div><span style='font-size: @respiratory_fontsize; color: #4efc03'>Respiratory: @respiratory</span></div>\n",
    "    <div><span style='font-size: @cold_fontsize; color: #2003fc'>Thermo cold: @thermo_cold</span></div>\n",
    "    <div><span style='font-size: @warm_fontsize; color: #fc03db'>Thermo warm: @thermo_warm</span></div>\n",
    "    <div><span style='font-size: @visual_fontsize; color: #03e8fc'>Visual: @visual{0.000}</span></div>\n",
    "</div>\n",
    "\"\"\"))\n",
    "\n",
    "renderer = plot.circle(\n",
    "    'x',\n",
    "    'y',\n",
    "    source=datasource,\n",
    "    color='colour',\n",
    "    legend_field = 'type_name',\n",
    "    line_alpha=0.6,\n",
    "    fill_alpha=0.6,\n",
    "    size=4, \n",
    "    selection_alpha=0.8,\n",
    "    nonselection_alpha=0.05\n",
    ")\n",
    "\n",
    "\n",
    "### Create a Select widget for type_name ###\n",
    "type_select = Select(title=\"Select Type:\", \n",
    "                     options=['all'] + list(in_from_senses_bk['type_name'].unique()), \n",
    "                     value=\"\")\n",
    "\n",
    "# Define a JavaScript callback function for the widget\n",
    "callback = CustomJS(args=dict(source=datasource, select=type_select), code=\"\"\"\n",
    "    const selected_type = select.value;\n",
    "    const indices = [];\n",
    "    const data = source.data;\n",
    "    const typeName = data.type_name;\n",
    "    for (let i = 0; i < typeName.length; i++) {\n",
    "        if (typeName[i] === selected_type || selected_type === \"all\") {\n",
    "            indices.push(i);\n",
    "        }\n",
    "    }\n",
    "    source.selected.indices = indices;\n",
    "    source.change.emit();\n",
    "\"\"\")\n",
    "# Attach the JavaScript callback function to the widget's value change event\n",
    "type_select.js_on_change('value', callback)\n",
    "\n",
    "plot.legend.location = \"top_left\"\n",
    "\n",
    "layout = column(type_select, plot)\n",
    "\n",
    "# show result\n",
    "show(layout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c9a83f-f257-490a-a981-882cc8dc112d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save it \n",
    "if savefig: \n",
    "    output_file(\"/Users/yijieyin/Downloads/interactive_umap_from_senses_by_type.html\")  # Specifies the output file\n",
    "    save(layout)  # Saves the plot to the file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24447aaa-f1cf-4dc6-a301-dbc4199353ce",
   "metadata": {},
   "source": [
    "#### sided input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed5e7d24-4ef7-4c35-ad3d-cc6764ce79f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_from_senses_sided = sensesn.T\n",
    "in_from_senses_sided['type_name'] = in_from_senses_sided.index.map(types)\n",
    "\n",
    "in_from_senses_data_sided = in_from_senses_sided.drop('type_name', axis = 1).values\n",
    "embedding_sided = reducer.fit_transform(in_from_senses_data_sided)\n",
    "embedding_sided.shape\n",
    "\n",
    "# umap \n",
    "reducer = umap.UMAP()\n",
    "\n",
    "# prepare data \n",
    "in_from_senses_bk_sided = pd.concat([in_from_senses_sided,\n",
    "           pd.DataFrame(embedding_sided, columns=('x', 'y'), index = in_from_senses_sided.index)], axis = 1)\n",
    "in_from_senses_bk_sided['colour'] = [typecolourdict[atype] for atype in in_from_senses_bk_sided.type_name]\n",
    "in_from_senses_bk_sided['name'] = [names[skid] for skid in in_from_senses_bk_sided.index]\n",
    "in_from_senses_bk_sided['type_add'] = [types_add[skid] for skid in in_from_senses_bk_sided.index]\n",
    "# change column names because bokeh doesn't like the dashes\n",
    "in_from_senses_bk_sided.rename(columns = {'gustatory-external':'gustatory_external', \n",
    "                                   'gustatory-pharyngeal':'gustatory_pharyngeal', \n",
    "                                   'thermo-cold':'thermo_cold', \n",
    "                                   'thermo-warm':'thermo_warm'}, inplace=True) \n",
    "round_cols = ['gustatory_external','gustatory_pharyngeal','thermo_cold','thermo_warm','enteric','olfactory','respiratory','visual']\n",
    "in_from_senses_bk_sided[round_cols] = in_from_senses_bk_sided[round_cols].round(3)\n",
    "\n",
    "# scale text size by value \n",
    "base = 10\n",
    "scale = 10\n",
    "in_from_senses_bk_sided['olfactory_fontsize'] = in_from_senses_bk_sided['olfactory'].apply(lambda x: str(base+int(x*scale))) # Adjust the scaling factor as needed\n",
    "in_from_senses_bk_sided['enteric_fontsize'] = in_from_senses_bk_sided['enteric'].apply(lambda x: str(base+int(x*scale)))\n",
    "in_from_senses_bk_sided['gustatory_external_fontsize'] = in_from_senses_bk_sided['gustatory_external'].apply(lambda x: str(base+int(x*scale)))\n",
    "in_from_senses_bk_sided['gustatory_pharyngeal_fontsize'] = in_from_senses_bk_sided['gustatory_pharyngeal'].apply(lambda x: str(base+int(x*scale)))\n",
    "in_from_senses_bk_sided['respiratory_fontsize'] = in_from_senses_bk_sided['respiratory'].apply(lambda x: str(base+int(x*scale)))\n",
    "in_from_senses_bk_sided['cold_fontsize'] = in_from_senses_bk_sided['thermo_cold'].apply(lambda x: str(base+int(x*scale)))\n",
    "in_from_senses_bk_sided['warm_fontsize'] = in_from_senses_bk_sided['thermo_warm'].apply(lambda x: str(base+int(x*scale)))\n",
    "in_from_senses_bk_sided['visual_fontsize'] = in_from_senses_bk_sided['visual'].apply(lambda x: str(base+int(x*scale)))\n",
    "\n",
    "# plotting \n",
    "datasource = ColumnDataSource(in_from_senses_bk_sided)\n",
    "\n",
    "plot = figure(\n",
    "    title='UMAP projection of input from senses',\n",
    "    width=800,\n",
    "#     plot_height=600,\n",
    "    tools=('pan, wheel_zoom, reset')\n",
    ")\n",
    "\n",
    "plot.add_tools(HoverTool(tooltips=\"\"\"\n",
    "<div>\n",
    "    <div><span style='font-size: 15px'> @type_name; @name: </span></div>\n",
    "    <div><span style='font-size: @olfactory_fontsize; color: #fc0303'>Olfactory: @olfactory{0.000}</span></div>\n",
    "    <div><span style='font-size: @enteric_fontsize; color: #224499'>Enteric: @enteric{0.000}</span></div>\n",
    "    <div><span style='font-size: @gustatory_external_fontsize; color: #fca103'>Gustatory external: @gustatory_external{0.000}</span></div>\n",
    "    <div><span style='font-size: @gustatory_pharyngeal_fontsize; color: #f8fc03'>Gustatory_pharyngeal: @gustatory_pharyngeal</span></div>\n",
    "    <div><span style='font-size: @respiratory_fontsize; color: #4efc03'>Respiratory: @respiratory</span></div>\n",
    "    <div><span style='font-size: @cold_fontsize; color: #2003fc'>Thermo cold: @thermo_cold</span></div>\n",
    "    <div><span style='font-size: @warm_fontsize; color: #fc03db'>Thermo warm: @thermo_warm</span></div>\n",
    "    <div><span style='font-size: @visual_fontsize; color: #03e8fc'>Visual: @visual{0.000}</span></div>\n",
    "</div>\n",
    "\"\"\"))\n",
    "\n",
    "renderer = plot.circle(\n",
    "    'x',\n",
    "    'y',\n",
    "    source=datasource,\n",
    "    color='colour',\n",
    "    legend_field = 'type_name',\n",
    "    line_alpha=0.6,\n",
    "    fill_alpha=0.6,\n",
    "    size=4, \n",
    "    selection_alpha=0.8,\n",
    "    nonselection_alpha=0.05\n",
    ")\n",
    "\n",
    "\n",
    "### Create a Select widget for type_name ###\n",
    "type_select = Select(title=\"Select Type:\", \n",
    "                     options=['all'] + list(in_from_senses_bk_sided['type_name'].unique()), \n",
    "                     value=\"\")\n",
    "\n",
    "# Define a JavaScript callback function for the widget\n",
    "callback = CustomJS(args=dict(source=datasource, select=type_select), code=\"\"\"\n",
    "    const selected_type = select.value;\n",
    "    const indices = [];\n",
    "    const data = source.data;\n",
    "    const typeName = data.type_name;\n",
    "    for (let i = 0; i < typeName.length; i++) {\n",
    "        if (typeName[i] === selected_type || selected_type === \"all\") {\n",
    "            indices.push(i);\n",
    "        }\n",
    "    }\n",
    "    source.selected.indices = indices;\n",
    "    source.change.emit();\n",
    "\"\"\")\n",
    "# Attach the JavaScript callback function to the widget's value change event\n",
    "type_select.js_on_change('value', callback)\n",
    "\n",
    "plot.legend.location = \"top_left\"\n",
    "\n",
    "layout = column(type_select, plot)\n",
    "\n",
    "# show result\n",
    "show(layout)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1885d006-ffb6-4d6b-b67a-3a392f691228",
   "metadata": {},
   "source": [
    "### all input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d2140d9-ee4a-46a8-81c4-ad50c7d726a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "reducer = umap.UMAP()\n",
    "\n",
    "in_from_senses_data = stepsn_noside.T.values\n",
    "embedding = reducer.fit_transform(in_from_senses_data)\n",
    "# embedding.shape: (1664, 2)\n",
    "\n",
    "# prepare the data\n",
    "all_sensory_bk = pd.concat([stepsn_noside.T,\n",
    "           pd.DataFrame(embedding, columns=('x', 'y'), index = in_from_senses.index)], axis = 1)\n",
    "all_sensory_bk = all_sensory_bk.round(3)\n",
    "\n",
    "# inherit the font size and meta information from in_from_senses_bk\n",
    "cols_to_merge = list(set(in_from_senses_bk.columns) - set(['x','y']))\n",
    "all_sensory_bk = pd.merge(all_sensory_bk, in_from_senses_bk[cols_to_merge], left_index=True, right_index=True)\n",
    "all_sensory_bk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f60bbde-cf89-4c2f-8914-a906a99ea47e",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasource = ColumnDataSource(all_sensory_bk)\n",
    "\n",
    "plot = figure(\n",
    "    title='UMAP projection of individual inputs [select type]',\n",
    "    width=1200,\n",
    "#     plot_height=600,\n",
    "    tools=('pan, wheel_zoom, reset')\n",
    ")\n",
    "\n",
    "plot.add_tools(HoverTool(tooltips=\"\"\"\n",
    "<div>\n",
    "    <div><span style='font-size: 15px'>@type_add; @name: </span></div>\n",
    "    <div><span style='font-size: @olfactory_fontsize; color: #fc0303'>Olfactory: @olfactory{0.000}</span></div>\n",
    "    <div><span style='font-size: @enteric_fontsize; color: #224499'>Enteric: @enteric{0.000}</span></div>\n",
    "    <div><span style='font-size: @gustatory_external_fontsize; color: #fca103'>Gustatory external: @gustatory_external{0.000}</span></div>\n",
    "    <div><span style='font-size: @gustatory_pharyngeal_fontsize; color: #f8fc03'>Gustatory_pharyngeal: @gustatory_pharyngeal</span></div>\n",
    "    <div><span style='font-size: @respiratory_fontsize; color: #4efc03'>Respiratory: @respiratory</span></div>\n",
    "    <div><span style='font-size: @cold_fontsize; color: #2003fc'>Thermo cold: @thermo_cold</span></div>\n",
    "    <div><span style='font-size: @warm_fontsize; color: #fc03db'>Thermo warm: @thermo_warm</span></div>\n",
    "    <div><span style='font-size: @visual_fontsize; color: #03e8fc'>Visual: @visual{0.000}</span></div>\n",
    "</div>\n",
    "\"\"\"))\n",
    "\n",
    "renderer = plot.circle(\n",
    "    'x',\n",
    "    'y',\n",
    "    source=datasource,\n",
    "    color='colour',\n",
    "    legend_field = 'type_name',\n",
    "    line_alpha=0.6,\n",
    "    fill_alpha=0.6,\n",
    "    size=4, \n",
    "    selection_alpha=0.8,\n",
    "    nonselection_alpha=0.05\n",
    ")\n",
    "\n",
    "\n",
    "### Create a Select widget for type_name ###\n",
    "type_select = Select(title=\"Select Type:\", \n",
    "                     options=['all'] + list(all_sensory_bk['type_name'].unique()), \n",
    "                     value=\"\")\n",
    "\n",
    "# Define a JavaScript callback function for the widget\n",
    "callback = CustomJS(args=dict(source=datasource, select=type_select), code=\"\"\"\n",
    "    const selected_type = select.value;\n",
    "    const indices = [];\n",
    "    const data = source.data;\n",
    "    const typeName = data.type_name;\n",
    "    for (let i = 0; i < typeName.length; i++) {\n",
    "        if (typeName[i] === selected_type || selected_type === \"all\") {\n",
    "            indices.push(i);\n",
    "        }\n",
    "    }\n",
    "    source.selected.indices = indices;\n",
    "    source.change.emit();\n",
    "\"\"\")\n",
    "# Attach the JavaScript callback function to the widget's value change event\n",
    "type_select.js_on_change('value', callback)\n",
    "\n",
    "plot.legend.location = \"top_left\"\n",
    "\n",
    "layout = column(type_select, plot)\n",
    "\n",
    "# show result\n",
    "show(layout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "271255bc-d12b-44b5-8c5f-eee563482fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save it \n",
    "if savefig: \n",
    "    output_file(\"/Users/yijieyin/Downloads/interactive_umap_all_input_by_type.html\")  # Specifies the output file\n",
    "    save(layout)  # Saves the plot to the file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff09a3ef-f54c-4a7f-b371-90f81a201283",
   "metadata": {},
   "source": [
    "the types are in the names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7221dfe-0951-47c2-9087-1abdfb4ae718",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasource = ColumnDataSource(all_sensory_bk)\n",
    "s2 = ColumnDataSource(all_sensory_bk)\n",
    "\n",
    "plot = figure(\n",
    "    title='UMAP projection of individual inputs [select type - selective hover]',\n",
    "    width=1200,\n",
    "#     plot_height=600,\n",
    "    tools=('pan, wheel_zoom, reset')\n",
    ")\n",
    "\n",
    "renderer = plot.circle(\n",
    "    'x',\n",
    "    'y',\n",
    "    source=datasource,\n",
    "    color='colour',\n",
    "    legend_field = 'type_name',\n",
    "    line_alpha=0.6,\n",
    "    fill_alpha=0.6,\n",
    "    size=4, \n",
    "    selection_alpha=0.8,\n",
    "    nonselection_alpha=0.05\n",
    ")\n",
    "renderer2 = plot.circle(\n",
    "    'x',\n",
    "    'y',\n",
    "    source=s2,\n",
    "    alpha=0  # set alpha to 0 to make this renderer invisible\n",
    ")\n",
    "\n",
    "plot.add_tools(HoverTool(renderers=[renderer2], tooltips=\"\"\"\n",
    "<div>\n",
    "    <div><span style='font-size: 15px'>@type_add; @name: </span></div>\n",
    "    <div><span style='font-size: @olfactory_fontsize; color: #fc0303'>Olfactory: @olfactory{0.000}</span></div>\n",
    "    <div><span style='font-size: @enteric_fontsize; color: #224499'>Enteric: @enteric{0.000}</span></div>\n",
    "    <div><span style='font-size: @gustatory_external_fontsize; color: #fca103'>Gustatory external: @gustatory_external{0.000}</span></div>\n",
    "    <div><span style='font-size: @gustatory_pharyngeal_fontsize; color: #f8fc03'>Gustatory_pharyngeal: @gustatory_pharyngeal</span></div>\n",
    "    <div><span style='font-size: @respiratory_fontsize; color: #4efc03'>Respiratory: @respiratory</span></div>\n",
    "    <div><span style='font-size: @cold_fontsize; color: #2003fc'>Thermo cold: @thermo_cold</span></div>\n",
    "    <div><span style='font-size: @warm_fontsize; color: #fc03db'>Thermo warm: @thermo_warm</span></div>\n",
    "    <div><span style='font-size: @visual_fontsize; color: #03e8fc'>Visual: @visual{0.000}</span></div>\n",
    "</div>\n",
    "\"\"\"))\n",
    "\n",
    "### Create a Select widget for type_name ###\n",
    "type_select = Select(title=\"Select Type:\", \n",
    "                     options=['all'] + list(all_sensory_bk['type_name'].unique()), \n",
    "                     value=\"\")\n",
    "\n",
    "# Define a JavaScript callback function for the widget\n",
    "callback = CustomJS(args=dict(source1=datasource, source2=s2, select=type_select), code=\"\"\"\n",
    "    const selected_type = select.value;\n",
    "    const indices = [];\n",
    "    const data1 = source1.data;\n",
    "    const data2 = source2.data;\n",
    "    const typeName = data1.type_name;\n",
    "    for (let i = 0; i < typeName.length; i++) {\n",
    "        if (typeName[i] === selected_type || selected_type === \"all\") {\n",
    "            indices.push(i);\n",
    "        }\n",
    "    }\n",
    "    source1.selected.indices = indices;\n",
    "    source1.change.emit();\n",
    "\n",
    "    // Update the data of the second data source to match the selected data\n",
    "    for (let key in data2) {\n",
    "        data2[key] = data1[key].filter((_, i) => indices.includes(i));\n",
    "    }\n",
    "    source2.change.emit();\n",
    "\"\"\")\n",
    "\n",
    "# Attach the JavaScript callback function to the widget's value change event\n",
    "type_select.js_on_change('value', callback)\n",
    "\n",
    "plot.legend.location = \"top_left\"\n",
    "\n",
    "layout = column(type_select, plot)\n",
    "\n",
    "# show result\n",
    "show(layout)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf2bc2f-236d-466c-af0e-ddf86c274e71",
   "metadata": {},
   "source": [
    "#### with bar plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a3f5f5-c113-4dff-8c01-24997df90567",
   "metadata": {},
   "outputs": [],
   "source": [
    "stepsn_wmodal = stepsn_noside.copy()\n",
    "stepsn_wmodal['modality'] = [nametotype_add[name] for name in stepsn_wmodal.index]\n",
    "# remove things inside brackets to make x axis tick labels smaller \n",
    "stepsn_wmodal.index = [re.sub('\\(.*\\)', '', x) for x in stepsn_wmodal.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a121e9-e68d-49c7-8b0b-61187da08043",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary of empty ColumnDataSources, one for each modality\n",
    "# this specified the sequence of modalities to be plotted \n",
    "modalities = ['thermo-cold','thermo-warm','respiratory','visual','olfactory','enteric','gustatory-pharyngeal','gustatory-external']\n",
    "sources = {modality: ColumnDataSource(data=dict(index=stepsn_wmodal.index[stepsn_wmodal.modality.isin([modality])], \n",
    "                                                top=[0]*len(stepsn_wmodal.index[stepsn_wmodal.modality.isin([modality])]))) for modality in modalities}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb08607-359a-4864-b6dd-fd66e7c77076",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.layouts import row\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3875bd2d-f4b4-4ad3-b310-77a16203ccd4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a bar plot for each modality\n",
    "bar_plots = []\n",
    "for modality in modalities:\n",
    "    this_mod = stepsn_wmodal[stepsn_wmodal.modality.isin([modality])]\n",
    "    if modality in ['thermo-cold','thermo-warm']: \n",
    "        plot = figure(x_range = list(this_mod.index), title=modality, tools='box_select,reset, wheel_zoom', \n",
    "                     width = 200, height = 200)\n",
    "    elif modality in ['visual','respiratory']: \n",
    "        plot = figure(x_range = list(this_mod.index), title=modality, tools='box_select,reset, wheel_zoom', \n",
    "                     width = 400, height = 200)\n",
    "    else: \n",
    "        plot = figure(x_range = list(this_mod.index), title=modality, tools='box_select,reset, wheel_zoom', \n",
    "                     width = 1300, height = 150)\n",
    "    plot.vbar(x='index', top='top', source=sources[modality], width=0.5)\n",
    "    # rotate 45 degrees\n",
    "    plot.xaxis.major_label_orientation = math.pi/4\n",
    "    plot.xaxis.axis_label_text_font_size = \"2pt\"\n",
    "    plot.y_range = Range1d(0, 0.3)\n",
    "    bar_plots.append(plot)\n",
    "\n",
    "# scatter plot \n",
    "all_sensory_bk['neuron_name'] = all_sensory_bk.index\n",
    "datasource = ColumnDataSource(all_sensory_bk)\n",
    "s2 = ColumnDataSource(all_sensory_bk)\n",
    "\n",
    "plot = figure(\n",
    "    title='UMAP projection of individual inputs',\n",
    "    width=500,\n",
    "    height = 400,\n",
    "#     plot_height=600,\n",
    "    tools=('pan, wheel_zoom, reset, tap, lasso_select')\n",
    ")\n",
    "\n",
    "renderer = plot.circle(\n",
    "    'x',\n",
    "    'y',\n",
    "    source=datasource,\n",
    "    color='colour',\n",
    "    legend_field = 'type_name',\n",
    "    line_alpha=0.6,\n",
    "    fill_alpha=0.6,\n",
    "    size=4, \n",
    "    selection_alpha=1,\n",
    "    nonselection_alpha=0.05\n",
    ")\n",
    "# add a transparent one for selective hovering \n",
    "renderer2 = plot.circle(\n",
    "    'x',\n",
    "    'y',\n",
    "    source=s2,\n",
    "    alpha=0  # set alpha to 0 to make this renderer invisible\n",
    ")\n",
    "\n",
    "div = Div(text=\"Selected neuron name: \", width = 400)\n",
    "type_select = Select(title=\"Select Type:\", \n",
    "                     options=['all'] + list(all_sensory_bk['type_name'].unique()), \n",
    "                     value=\"\")\n",
    "\n",
    "# Define a JavaScript callback function for the widget\n",
    "type_select_callback = CustomJS(args=dict(source1=datasource, source2=s2, select=type_select, div = div), code=\"\"\"\n",
    "    const selected_type = select.value;\n",
    "    const indices = [];\n",
    "    const names = []; \n",
    "    const data1 = source1.data;\n",
    "    const data2 = source2.data;\n",
    "    const typeName = data1.type_name;\n",
    "    const allNames = data1.neuron_name; \n",
    "    for (let i = 0; i < typeName.length; i++) {\n",
    "        if (typeName[i] === selected_type || selected_type === \"all\") {\n",
    "            indices.push(i);\n",
    "            if (selected_type !== 'all'){\n",
    "                names.push(allNames[i]); \n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    source1.selected.indices = indices;\n",
    "    source1.change.emit();\n",
    "    div.text = 'Selected neuron name: ' + names; \n",
    "    \n",
    "    // Update the data of the second data source to match the selected data\n",
    "    for (let key in data2) {\n",
    "        data2[key] = data1[key].filter((_, i) => indices.includes(i));\n",
    "    }\n",
    "    source2.change.emit();\n",
    "    \n",
    "    \"\"\")\n",
    "type_select.js_on_change('value', type_select_callback)\n",
    "\n",
    "lasso_callback = CustomJS(args=dict(source=datasource, div=div), code=\"\"\"\n",
    "    const indices = source.selected.indices;\n",
    "    const original_indices = indices.map(i => source.data.neuron_name[i]);\n",
    "    const original_indices_string = original_indices.join(\", \");\n",
    "    // Update the text of the Div\n",
    "    div.text = \"Selected Indices: \" + original_indices_string;\n",
    "\"\"\")\n",
    "\n",
    "plot.js_on_event('selectiongeometry', lasso_callback)\n",
    "\n",
    "\n",
    "# Define a JavaScript callback to update 'stepsn_source' when a circle is selected\n",
    "stepsn_wmodal_source = ColumnDataSource(stepsn_wmodal)\n",
    "callback = CustomJS(args=dict(source=datasource, \n",
    "                              sources = sources, \n",
    "                              stepsn_wmodal = stepsn_wmodal_source, \n",
    "                             div = div), \n",
    "                    code=\"\"\"\n",
    "    var selected_indices = source.selected.indices;\n",
    "    if (selected_indices.length == 0) {\n",
    "        return;\n",
    "    }    \n",
    "    var selected_skid = source.data['neuron_name'][selected_indices[0]];\n",
    "    div.text = \"Selected neuron name: \" + selected_skid;\n",
    "\n",
    "    // update bar plots \n",
    "    for (var modality in sources) {\n",
    "    var source_to_update = sources[modality];\n",
    "\n",
    "    var new_data = [];\n",
    "    for (var i = 0; i < stepsn_wmodal.data['modality'].length; i++) {\n",
    "        if (stepsn_wmodal.data['modality'][i] === modality) {\n",
    "            new_data.push(stepsn_wmodal.data[selected_skid][i]);\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    source_to_update.data['top'] = new_data;\n",
    "    source_to_update.change.emit();\n",
    "    \n",
    "    \n",
    "}\n",
    "\n",
    "\"\"\")\n",
    "\n",
    "plot.js_on_event(events.Tap, callback)\n",
    "\n",
    "\n",
    "# add text on hover \n",
    "plot.add_tools(HoverTool(renderers=[renderer2], tooltips=\"\"\"\n",
    "<div>\n",
    "    <div><span style='font-size: 15px'>@type_add; @name: </span></div>\n",
    "    <div><span style='font-size: @olfactory_fontsize; color: #fc0303'>Olfactory: @olfactory{0.000}</span></div>\n",
    "    <div><span style='font-size: @enteric_fontsize; color: #224499'>Enteric: @enteric{0.000}</span></div>\n",
    "    <div><span style='font-size: @gustatory_external_fontsize; color: #fca103'>Gustatory external: @gustatory_external{0.000}</span></div>\n",
    "    <div><span style='font-size: @gustatory_pharyngeal_fontsize; color: #f8fc03'>Gustatory_pharyngeal: @gustatory_pharyngeal</span></div>\n",
    "    <div><span style='font-size: @respiratory_fontsize; color: #4efc03'>Respiratory: @respiratory</span></div>\n",
    "    <div><span style='font-size: @cold_fontsize; color: #2003fc'>Thermo cold: @thermo_cold</span></div>\n",
    "    <div><span style='font-size: @warm_fontsize; color: #fc03db'>Thermo warm: @thermo_warm</span></div>\n",
    "    <div><span style='font-size: @visual_fontsize; color: #03e8fc'>Visual: @visual{0.000}</span></div>\n",
    "</div>\n",
    "\"\"\"))\n",
    "\n",
    "plot.legend.location = \"top_right\"\n",
    "plot.legend.label_text_font_size = '8pt'\n",
    "\n",
    "# Combine all plots together\n",
    "layout = column(row(column(*bar_plots[0:2]), plot, column(*bar_plots[2:4]), column(type_select, div)), *bar_plots[4:])\n",
    "# layout = column(row(plot, *bar_plots[4:]), *bar_plots[0:4])\n",
    "\n",
    "# Show the result\n",
    "show(layout)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9069c79-1ba9-4ebb-8147-bf608abe3bb1",
   "metadata": {},
   "source": [
    "TODO take max\n",
    "PN-somato: mechanosensory, nociceptive \n",
    "would be nice if it's in CATMAID \n",
    "DANg1 and DANi1 are very similar in the plot above. Perhaps sign flip somewhere? \n",
    "Eschbach & Fushiki paper: feedback and feed across - cross compartment neurons - look for these for these DANs \n",
    "appetitive DANs that synapse to MBONs that are aversive \n",
    "    stimulate appetitive DAN compartment \n",
    "    learning involves depression of KC-MBON synapse\n",
    "some MBONs of the medial lobe might be inhibitory \n",
    "associate with appetitive reward, weaken i1 \n",
    "look at the feed across motifs and MBON i1 and g1 - try to make sense of that. \n",
    "go from ORNS with valences to the i1 and g1. \n",
    "    and what happens afterwards? \n",
    "you can have a section of this on your thesis \n",
    "aversive together \n",
    "j1 distant \n",
    "all the narrative for DANs and MBINs \n",
    "b1&b2 similar \n",
    "PED different from VL and ML "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b88ee7d-02e2-444c-bb15-766242dcea65",
   "metadata": {},
   "source": [
    "#### sided"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d342cdd-6e6b-47c1-8141-9c677cb149a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "reducer = umap.UMAP()\n",
    "\n",
    "in_from_senses_data = stepsn.T.values\n",
    "embedding = reducer.fit_transform(in_from_senses_data)\n",
    "embedding.shape\n",
    "\n",
    "# prepare the data\n",
    "all_sensory_bk_sided = pd.concat([stepsn.T,\n",
    "           pd.DataFrame(embedding, columns=('x', 'y'), index = stepsn.T.index)], axis = 1)\n",
    "all_sensory_bk_sided = all_sensory_bk_sided.round(3)\n",
    "all_sensory_bk_sided['side'] = [sides[skid] for skid in all_sensory_bk_sided.index]\n",
    "\n",
    "# inherit the font size and meta information from in_from_senses_bk\n",
    "cols_to_merge = list(set(in_from_senses_bk_sided.columns) - set(['x','y']))\n",
    "all_sensory_bk_sided = pd.merge(all_sensory_bk_sided, in_from_senses_bk_sided[cols_to_merge], left_index=True, right_index=True)\n",
    "all_sensory_bk_sided"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5aa6f86-38d9-4644-9e7e-09081113d8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Â plotting \n",
    "datasource = ColumnDataSource(all_sensory_bk_sided)\n",
    "\n",
    "plot = figure(\n",
    "    title='UMAP projection of individual inputs',\n",
    "    width=1200,\n",
    "#     plot_height=600,\n",
    "    tools=('pan, wheel_zoom, reset')\n",
    ")\n",
    "\n",
    "plot.add_tools(HoverTool(tooltips=\"\"\"\n",
    "<div>\n",
    "    <div><span style='font-size: 15px'>@type_add; @name; @side: </span></div>\n",
    "    <div><span style='font-size: @olfactory_fontsize; color: #fc0303'>Olfactory: @olfactory{0.000}</span></div>\n",
    "    <div><span style='font-size: @enteric_fontsize; color: #224499'>Enteric: @enteric{0.000}</span></div>\n",
    "    <div><span style='font-size: @gustatory_external_fontsize; color: #fca103'>Gustatory external: @gustatory_external{0.000}</span></div>\n",
    "    <div><span style='font-size: @gustatory_pharyngeal_fontsize; color: #f8fc03'>Gustatory_pharyngeal: @gustatory_pharyngeal</span></div>\n",
    "    <div><span style='font-size: @respiratory_fontsize; color: #4efc03'>Respiratory: @respiratory</span></div>\n",
    "    <div><span style='font-size: @cold_fontsize; color: #2003fc'>Thermo cold: @thermo_cold</span></div>\n",
    "    <div><span style='font-size: @warm_fontsize; color: #fc03db'>Thermo warm: @thermo_warm</span></div>\n",
    "    <div><span style='font-size: @visual_fontsize; color: #03e8fc'>Visual: @visual{0.000}</span></div>\n",
    "</div>\n",
    "\"\"\"))\n",
    "\n",
    "renderer = plot.circle(\n",
    "    'x',\n",
    "    'y',\n",
    "    source=datasource,\n",
    "    color='colour',\n",
    "    legend_field = 'type_name',\n",
    "    line_alpha=0.6,\n",
    "    fill_alpha=0.6,\n",
    "    size=4, \n",
    "    selection_alpha=0.8,\n",
    "    nonselection_alpha=0.05\n",
    ")\n",
    "\n",
    "\n",
    "### Create a Select widget for type_name ###\n",
    "type_select = Select(title=\"Select Type:\", \n",
    "                     options=['all'] + list(all_sensory_bk_sided['type_name'].unique()), \n",
    "                     value=\"\")\n",
    "\n",
    "side_select = Select(title=\"Select Side:\", \n",
    "                     options=['all'] + list(all_sensory_bk_sided['side'].unique()), \n",
    "                     value=\"\")\n",
    "\n",
    "\n",
    "# Define a JavaScript callback function for the widget\n",
    "callback = CustomJS(args=dict(source=datasource, select_type=type_select, select_side=side_select), code=\"\"\"\n",
    "    const selected_type = select_type.value;\n",
    "    const selected_side = select_side.value;\n",
    "    const indices = [];\n",
    "    const data = source.data;\n",
    "    const typeName = data.type_name;\n",
    "    const sideName = data.side;\n",
    "    for (let i = 0; i < typeName.length; i++) {\n",
    "        if ((typeName[i] === selected_type || selected_type === \"all\") &&\n",
    "            (sideName[i] === selected_side || selected_side === \"all\")) {\n",
    "            indices.push(i);\n",
    "        }\n",
    "    }\n",
    "    source.selected.indices = indices;\n",
    "    source.change.emit();\n",
    "\"\"\")\n",
    "\n",
    "# Attach the JavaScript callback function to the widget's value change event\n",
    "type_select.js_on_change('value', callback)\n",
    "side_select.js_on_change('value', callback)\n",
    "\n",
    "plot.legend.location = \"top_left\"\n",
    "\n",
    "layout = column(row(type_select, side_select), plot)\n",
    "\n",
    "# show result\n",
    "show(layout)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fec2c0d-ff0b-4628-a93b-4b4e54237117",
   "metadata": {},
   "source": [
    "##### skid select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51363a24-3949-42f8-8524-25c3586f93cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasource = ColumnDataSource(all_sensory_bk_sided)\n",
    "\n",
    "plot = figure(\n",
    "    title='UMAP projection of individual inputs [query by skid]',\n",
    "    width=1200,\n",
    "#     plot_height=600,\n",
    "    tools=('pan, wheel_zoom, reset')\n",
    ")\n",
    "\n",
    "plot.add_tools(HoverTool(tooltips=\"\"\"\n",
    "<div>\n",
    "    <div><span style='font-size: 15px'>@type_add; @name: </span></div>\n",
    "    <div><span style='font-size: @olfactory_fontsize; color: #fc0303'>Olfactory: @olfactory{0.000}</span></div>\n",
    "    <div><span style='font-size: @enteric_fontsize; color: #224499'>Enteric: @enteric{0.000}</span></div>\n",
    "    <div><span style='font-size: @gustatory_external_fontsize; color: #fca103'>Gustatory external: @gustatory_external{0.000}</span></div>\n",
    "    <div><span style='font-size: @gustatory_pharyngeal_fontsize; color: #f8fc03'>Gustatory_pharyngeal: @gustatory_pharyngeal</span></div>\n",
    "    <div><span style='font-size: @respiratory_fontsize; color: #4efc03'>Respiratory: @respiratory</span></div>\n",
    "    <div><span style='font-size: @cold_fontsize; color: #2003fc'>Thermo cold: @thermo_cold</span></div>\n",
    "    <div><span style='font-size: @warm_fontsize; color: #fc03db'>Thermo warm: @thermo_warm</span></div>\n",
    "    <div><span style='font-size: @visual_fontsize; color: #03e8fc'>Visual: @visual{0.000}</span></div>\n",
    "</div>\n",
    "\"\"\"))\n",
    "\n",
    "renderer = plot.circle(\n",
    "    'x',\n",
    "    'y',\n",
    "    source=datasource,\n",
    "    color='colour',\n",
    "    legend_field = 'type_name',\n",
    "    line_alpha=0.6,\n",
    "    fill_alpha=0.6,\n",
    "    size=4, \n",
    "    selection_alpha=0.8,\n",
    "    nonselection_alpha=0.05\n",
    ")\n",
    "\n",
    "### select skids ### \n",
    "# Create a TextInput widget for entering comma-separated indices\n",
    "index_input = TextInput(placeholder=\"Enter ids (comma-separated)\", width = 200)\n",
    "\n",
    "callback = CustomJS(args=dict(source=datasource, index_input=index_input), code=\"\"\"\n",
    "    const indices_str = index_input.value;\n",
    "    const indices = indices_str.split(\",\").map(x => x.trim());\n",
    "    console.log(\"Indices:\", indices);\n",
    "    const data = source.data;\n",
    "    const index_values = data.index;\n",
    "    console.log(\"Index Values:\", index_values);\n",
    "    const selected_indices = [];\n",
    "\n",
    "    for (let i = 0; i < indices.length; i++) {\n",
    "        const index = indices[i];\n",
    "        console.log(\"Checking index:\", index);\n",
    "        if (index_values.includes(index)) {\n",
    "            selected_indices.push(index_values.indexOf(index));\n",
    "        }\n",
    "    }\n",
    "\n",
    "    console.log(\"Selected Indices:\", selected_indices);\n",
    "    source.selected.indices = selected_indices.map(i => parseInt(i));\n",
    "    source.change.emit();\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "# Attach the JavaScript callback function to the widget's value change event\n",
    "index_input.js_on_change('value', callback)\n",
    "\n",
    "plot.legend.location = \"top_left\"\n",
    "\n",
    "layout = column(index_input, plot)\n",
    "\n",
    "# show result\n",
    "show(layout)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ed2c05-9435-49e3-b0ea-3f549b99d76e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save it \n",
    "if savefig: \n",
    "    output_file(\"/Users/yijieyin/Downloads/interactive_umap_all_input_by_skid.html\")  # Specifies the output file\n",
    "    save(layout)  # Saves the plot to the file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e9380d-7207-48ca-94d2-f846c05f92c3",
   "metadata": {},
   "source": [
    "##### lasso select + skid select \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c96e6e77-1be4-4e39-b771-50b9d5af9676",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_sensory_bk = all_sensory_bk.reset_index().rename(columns={'index': 'skid'})\n",
    "all_sensory_bk_sided['skid'] = all_sensory_bk_sided.index\n",
    "\n",
    "datasource = ColumnDataSource(all_sensory_bk_sided)\n",
    "\n",
    "plot = figure(\n",
    "    title='UMAP projection of individual inputs [query by skid + lasso select]',\n",
    "#     width=1200,\n",
    "#     plot_height=600,\n",
    "    tools=('pan, wheel_zoom, reset, lasso_select')\n",
    ")\n",
    "\n",
    "renderer = plot.circle(\n",
    "    'x',\n",
    "    'y',\n",
    "    source=datasource,\n",
    "    color='colour',\n",
    "    legend_field = 'type_name',\n",
    "    line_alpha=0.6,\n",
    "    fill_alpha=0.6,\n",
    "    size=4, \n",
    "    selection_alpha=1,\n",
    "    nonselection_alpha=0.05\n",
    ")\n",
    "\n",
    "### select skids ### \n",
    "# Create a TextInput widget for entering comma-separated indices\n",
    "index_input = TextInput(placeholder=\"Enter ids (comma-separated)\", width = 200)\n",
    "\n",
    "callback = CustomJS(args=dict(source=datasource, index_input=index_input), code=\"\"\"\n",
    "    const indices_str = index_input.value;\n",
    "    const indices = indices_str.split(\",\").map(x => x.trim());\n",
    "    console.log(\"Indices:\", indices);\n",
    "    const data = source.data;\n",
    "    const index_values = data.index;\n",
    "    console.log(\"Index Values:\", index_values);\n",
    "    const selected_indices = [];\n",
    "\n",
    "    for (let i = 0; i < indices.length; i++) {\n",
    "        const index = indices[i];\n",
    "        console.log(\"Checking index:\", index);\n",
    "        if (index_values.includes(index)) {\n",
    "            selected_indices.push(index_values.indexOf(index));\n",
    "        }\n",
    "    }\n",
    "\n",
    "    console.log(\"Selected Indices:\", selected_indices);\n",
    "    source.selected.indices = selected_indices.map(i => parseInt(i));\n",
    "    source.change.emit();\n",
    "\"\"\")\n",
    "\n",
    "# Attach the JavaScript callback function to the widget's value change event\n",
    "index_input.js_on_change('value', callback)\n",
    "\n",
    "# Define a Div object\n",
    "div = Div(text=\"\")\n",
    "### lasso select ### \n",
    "lasso_callback = CustomJS(args=dict(source=datasource, div=div), code=\"\"\"\n",
    "    const indices = source.selected.indices;\n",
    "    const original_indices = indices.map(i => source.data.skid[i]);\n",
    "    const original_indices_string = original_indices.join(\", \");\n",
    "    // Update the text of the Div\n",
    "    div.text = \"Selected Indices: \" + original_indices_string;\n",
    "\"\"\")\n",
    "\n",
    "plot.js_on_event('selectiongeometry', lasso_callback)\n",
    "\n",
    "plot.add_tools(HoverTool(tooltips=\"\"\"\n",
    "<div>\n",
    "    <div><span style='font-size: 15px'>@type_add; @name: </span></div>\n",
    "    <div><span style='font-size: @olfactory_fontsize; color: #fc0303'>Olfactory: @olfactory{0.000}</span></div>\n",
    "    <div><span style='font-size: @enteric_fontsize; color: #224499'>Enteric: @enteric{0.000}</span></div>\n",
    "    <div><span style='font-size: @gustatory_external_fontsize; color: #fca103'>Gustatory external: @gustatory_external{0.000}</span></div>\n",
    "    <div><span style='font-size: @gustatory_pharyngeal_fontsize; color: #f8fc03'>Gustatory_pharyngeal: @gustatory_pharyngeal</span></div>\n",
    "    <div><span style='font-size: @respiratory_fontsize; color: #4efc03'>Respiratory: @respiratory</span></div>\n",
    "    <div><span style='font-size: @cold_fontsize; color: #2003fc'>Thermo cold: @thermo_cold</span></div>\n",
    "    <div><span style='font-size: @warm_fontsize; color: #fc03db'>Thermo warm: @thermo_warm</span></div>\n",
    "    <div><span style='font-size: @visual_fontsize; color: #03e8fc'>Visual: @visual{0.000}</span></div>\n",
    "</div>\n",
    "\"\"\"))\n",
    "\n",
    "plot.legend.location = \"top_left\"\n",
    "\n",
    "layout = column(index_input, plot, div)\n",
    "\n",
    "# show result\n",
    "show(layout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ada527-e088-4613-abc5-5cfa1493ecaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save it \n",
    "savefig = True\n",
    "if savefig: \n",
    "    output_file(\"/Users/yijieyin/Downloads/interactive_umap_all_input_by_skid_lasso.html\")  # Specifies the output file\n",
    "    save(layout)  # Saves the plot to the file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84b33ddc-6eaf-444f-ba70-45444ba084a0",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Zooming in "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91a2fb0e-c015-4c50-9325-e3adbb3eb5f0",
   "metadata": {},
   "source": [
    "##Â ORNs-DANs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f8ea32-cd2d-46e1-8d6a-22a674d92c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "orndan = stepsn.loc[[types_add[skid] =='olfactory' for skid in stepsn.index], \n",
    "                    [types[skid] =='MBIN' for skid in stepsn.columns]]\n",
    "# change skid to neuron names in the columns and rows \n",
    "colnames = [types_add[skid]+'_'+sides[skid] for skid in orndan.columns]\n",
    "# colnames = [types_add[skid] for skid in orndan.columns]\n",
    "rownames = [names[skid] for skid in orndan.index]\n",
    "orndan.columns = colnames\n",
    "orndan.index = rownames\n",
    "colnames.sort()\n",
    "rownames.sort()\n",
    "orndan = orndan.loc[rownames,colnames]\n",
    "orndan.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc643da-9cc7-47f1-9dcd-bc57ad09a300",
   "metadata": {},
   "outputs": [],
   "source": [
    "vmin = orndan.min().min()\n",
    "vmax = orndan.max().max()\n",
    "\n",
    "orndan_dp = orndan.style.background_gradient(cmap='Blues', vmin = vmin, vmax = vmax)\n",
    "display(orndan_dp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfcf1f04-416a-43ee-aaf8-44a3bc1189ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# how much of DAN's input come from ORNs? \n",
    "orndan.sum(axis = 'rows').hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb8d238-3022-497f-9bac-7b3a1fd5cc9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# how much input does each ORN account for? \n",
    "orndan.stack().plot.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ae59c6c-ded3-4014-bf53-2022810556de",
   "metadata": {},
   "source": [
    "## ORNs-KCs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28498ffd-811d-416a-90e9-6e25d89cccdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ornkc = stepsn.loc[[types_add[skid] =='olfactory' for skid in stepsn.index], \n",
    "                    [types[skid] =='KC' for skid in stepsn.columns]]\n",
    "rownames = [names[skid] for skid in ornkc.index]\n",
    "ornkc.index = rownames\n",
    "rownames.sort()\n",
    "ornkc = ornkc.loc[rownames,:]\n",
    "ornkc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee66328f-d5df-45df-87a5-bb07ab24bcac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# how much of KC's input come from ORNs? \n",
    "ornkc.sum(axis = 'rows').hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b5102c5-8233-4e17-8bb9-1e7bf3c34eee",
   "metadata": {},
   "source": [
    "More than DANs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dbb72b9-9fd3-483a-893c-3a05730428f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "vmin = ornkc.min().min()\n",
    "vmax = ornkc.max().max()\n",
    "\n",
    "ornkc_dp = ornkc.style.background_gradient(cmap='Blues', vmin = vmin, vmax = vmax)\n",
    "display(ornkc_dp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7db51b-cb85-405e-957d-c9cf69ab1aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# how much input does each ORN account for? \n",
    "ornkc.stack().plot.hist(bins = 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de056442-771c-4608-85b4-1cde589c7833",
   "metadata": {},
   "source": [
    "## colours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a60218-5f47-4102-9f16-00a6858a9124",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a dictionary of colours \n",
    "kcdancols = sns.color_palette(\"icefire\", n_colors=len(dans_sensein.cell_type.unique()))\n",
    "# KC is yellow \n",
    "kcdancols.append(\"yellow\")\n",
    "kcdan_col = dict(zip(np.append(dans_sensein.cell_type.unique(),['KC']), \n",
    "                     kcdancols.as_hex()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dfa2873-9336-4702-ada8-f2a8eabb23bb",
   "metadata": {},
   "source": [
    "## ORN-KC vs. ORN-DAN comparison\n",
    "### dimensionality reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ada07d-8898-4698-a4c7-364a47ec42a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA()\n",
    "x = pd.concat([ornkc.T, orndan.T])\n",
    "x_pca = pca.fit_transform(x)\n",
    "x_pca = pd.DataFrame(x_pca)\n",
    "x_pca.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fcf072a-bc8b-49fa-93d4-d002146b7a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a70b9bc-995a-4e1d-8fb9-a66260b7b6d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_pca.columns = ['PC{}'.format(n) for n in range(x_pca.shape[1])]\n",
    "x_pca.index = x.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f7e1cb1-849f-49bd-b4c2-64b359a78209",
   "metadata": {},
   "outputs": [],
   "source": [
    "kcdan_col_side = kcdan_col.copy()\n",
    "for dan in kcdan_col.keys(): \n",
    "    # add names with sides \n",
    "    kcdan_col_side[dan+'_left'] = kcdan_col[dan]\n",
    "    kcdan_col_side[dan+'_right'] = kcdan_col[dan]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbac4ada-6057-4680-b666-3aaa5b627576",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select specific cell types to colour \n",
    "x_pca['cell_type']= [idx if '_' in idx else types_add[idx] for idx in x_pca.index]\n",
    "# filter if desired \n",
    "# x_pca = x_pca[['_' in atype for atype in x_pca.cell_type]]\n",
    "\n",
    "fig = plt.figure(figsize = (20,12))\n",
    "ax = fig.add_subplot(1,1,1) \n",
    "ax.set_xlabel('Principal Component 1') \n",
    "ax.set_ylabel('Principal Component 2') \n",
    "ax.set_title('2 component PCA on ORN connections') \n",
    "\n",
    "# targets = x_pca.cell_type.unique()\n",
    "# colors = sns.color_palette(\"icefire\", len(targets)).as_hex()\n",
    "for target, color in kcdan_col_side.items():\n",
    " indicesToKeep = x_pca['cell_type'] == target\n",
    " ax.scatter(x_pca.loc[indicesToKeep, 'PC1']\n",
    " , x_pca.loc[indicesToKeep, 'PC2']\n",
    " , c = color\n",
    " , s = 50)\n",
    "ax.legend(kcdan_col)\n",
    "ax.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb063be-8c31-4486-9293-1f377d8d529d",
   "metadata": {},
   "source": [
    "Very little variance explained by the first two components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdaa5742-695e-43a6-83d4-7b874e6c4d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot DANs only \n",
    "# select specific cell types to colour \n",
    "x_pca['cell_type']= [idx if '_' in idx else types_add[idx] for idx in x_pca.index]\n",
    "# filter if desired \n",
    "x_pca_f = x_pca[['_' in atype for atype in x_pca.cell_type]]\n",
    "\n",
    "fig = plt.figure(figsize = (20,12))\n",
    "ax = fig.add_subplot(1,1,1) \n",
    "ax.set_xlabel('Principal Component 1') \n",
    "ax.set_ylabel('Principal Component 2') \n",
    "ax.set_title('2 component PCA') \n",
    "\n",
    "# targets = x_pca.cell_type.unique()\n",
    "# colors = sns.color_palette(\"icefire\", len(targets)).as_hex()\n",
    "for target, color in kcdan_col_side.items():\n",
    " indicesToKeep = x_pca_f['cell_type'] == target\n",
    " ax.scatter(x_pca_f.loc[indicesToKeep, 'PC1']\n",
    " , x_pca_f.loc[indicesToKeep, 'PC2']\n",
    " , c = color\n",
    " , s = 50)\n",
    "ax.legend(kcdan_col)\n",
    "ax.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bc7dbf7-ed06-4b0b-a175-a7da31bf060b",
   "metadata": {},
   "source": [
    "Perhaps dimensionality reduction wasn't the way to go, because there are many more KCs than DANs, so dimensionality reduction would pay more attention to KCs presumably. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6279ce15-614e-4c0c-87ab-03cccb966feb",
   "metadata": {},
   "source": [
    "###Â add valence of ORNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd11dc7-0df5-4444-8817-7c964ed56f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "ornv = {\n",
    "    '22c': 'negative', \n",
    "    '47a': 'negative',\n",
    "    '85c': 'neutral',\n",
    "    '24a': 'positive', \n",
    "    '42a': 'positive', \n",
    "    '42b': 'positive', \n",
    "    '82a': 'positive', \n",
    "    '83a': 'unknown', \n",
    "    '35a': 'positive', \n",
    "    '45a': 'positive',\n",
    "    '30a': 'neutral', \n",
    "    '59a': 'negative', \n",
    "    '63a': 'unknown', \n",
    "    '67b': 'positive', \n",
    "    '94a': 'positive', \n",
    "    '1a': 'negative', \n",
    "    '45b': 'negative', \n",
    "    '49a': 'negative', \n",
    "    '33a': 'unknown'}    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "049ec101-05e3-49b9-911c-420e6102f037",
   "metadata": {},
   "outputs": [],
   "source": [
    "ornkcdan = pd.concat([ornkc, orndan], axis=1)\n",
    "vs = []\n",
    "for typeside in ornkcdan.index: \n",
    "    # valence from thesis \n",
    "    vfromthesis = [ornv[key] for key in ornv.keys() if key in typeside]\n",
    "    if len(vfromthesis)==0: \n",
    "        vs.append('unknown')\n",
    "    else: \n",
    "        vs.append(vfromthesis[0])\n",
    "ornkcdan['valence'] = vs\n",
    "ornkcdan.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b06fa5c6-8f61-4929-9c9b-c7972db60188",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# could sort values using the following line: \n",
    "# ornkcdanv = ornkcdan.groupby('valence').sum().T.sort_values(['negative','positive'])\n",
    "ornkcdanv = ornkcdan.groupby('valence').sum().T\n",
    "\n",
    "vmin = ornkcdanv.min().min()\n",
    "vmax = ornkcdanv.max().max()\n",
    "\n",
    "ornkcdanv_dp = ornkcdanv.style.background_gradient(cmap='Blues', vmin = vmin, vmax = vmax)\n",
    "display(ornkcdanv_dp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "777c9b99-bce2-4092-b33c-39d91f678843",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a dictionary of ORN skids and valences \n",
    "ornskids = [skid for skid, name in names.items() if ' ORN ' in name]\n",
    "orn_skid_v = dict() \n",
    "for skid in ornskids: \n",
    "    key = [key for key in ornv.keys() if key in names[skid]]\n",
    "    if len(key)==0:\n",
    "        orn_skid_v[skid] = 'unknown'\n",
    "    else: \n",
    "        orn_skid_v[skid] = ornv[key[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef081970-1c8a-4543-9596-a44a6458f4e4",
   "metadata": {},
   "source": [
    "#### show path lengths with cumulative plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c207aa1-5dc8-47d3-9bfb-883bad96bf9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ns = [skid for skid, name in types_add.items() if 'DAN-j1' in name]\n",
    "inv = ['positive','negative']\n",
    "v_colour = {'positive':'red', 'negative':'blue'}\n",
    "side_linetype = {'left':'-', 'right':'--'}\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (15,10))\n",
    "# n has to be one skid at a time, because you can't add input proportions \n",
    "for n in ns: \n",
    "    for v in inv: \n",
    "        ys = [] \n",
    "        skids = [key for key,value in orn_skid_v.items() if value==v]\n",
    "\n",
    "        for i in range(len(steps_nosense)): \n",
    "            this_step = steps_nosense[i]\n",
    "            selected_inprop = this_step.loc[this_step.index.isin(skids), this_step.columns.isin([n])]\n",
    "            # sum across columns / postsynaptic \n",
    "            ys.append(selected_inprop.sum(axis = 0))\n",
    "        \n",
    "        # plotting \n",
    "        plt.plot([i+1 for i in range(len(steps_nosense))], \n",
    "                 ys, \n",
    "                 side_linetype[sides[n]], \n",
    "                 color = v_colour[v], \n",
    "                label = sides[n])\n",
    "plt.xlabel('Steps from the senses')\n",
    "plt.ylabel('Percentage input accounted for')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c654ccbd-73b1-4a12-b131-7e7983cb4c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cumulative plot \n",
    "ns = [skid for skid, name in types_add.items() if 'DAN-j1' in name]\n",
    "inv = ['positive','negative']\n",
    "v_colour = {'positive':'red', 'negative':'blue'}\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (15,20))\n",
    "# n has to be one skid at a time, because you can't add input proportions \n",
    "for n in ns: \n",
    "    for v in inv: \n",
    "        ys = [] \n",
    "        skids = [key for key,value in orn_skid_v.items() if value==v]\n",
    "\n",
    "        for i in range(len(steps_nosense)): \n",
    "            this_step = steps_nosense[i]\n",
    "            selected_inprop = this_step.loc[this_step.index.isin(skids), this_step.columns.isin([n])]\n",
    "            # sum across columns / postsynaptic \n",
    "            if i==0: \n",
    "                ys.append(selected_inprop.sum(axis = 0))\n",
    "            else: \n",
    "                ys.append(ys[-1] + selected_inprop.sum(axis = 0))\n",
    "        \n",
    "        # plotting \n",
    "        plt.plot([i+1 for i in range(len(steps_nosense))], \n",
    "                 ys, \n",
    "                 color = v_colour[v])\n",
    "plt.xlabel('Steps from the senses')\n",
    "plt.ylabel('Percentage input accounted for')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fee59ff-fd56-4526-aea6-b1c3f5fef55a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (15,10))\n",
    "\n",
    "for ctype, col in kcdan_col_side.items(): \n",
    "    if '_' in ctype: \n",
    "        continue \n",
    "    elif ctype=='KC':\n",
    "        sel = ornkcdanv.loc[['_' not in cell_type for cell_type in ornkcdanv.index]]\n",
    "        ax.scatter(sel.positive, sel.negative, color = kcdan_col_side[ctype], label = ctype)\n",
    "    else: \n",
    "        sel = ornkcdanv.loc[[ctype in cell_type for cell_type in ornkcdanv.index]]\n",
    "        ax.scatter(sel.positive, sel.negative, color = kcdan_col_side[ctype], label = ctype)\n",
    "\n",
    "ax.set_xlabel('Positive')\n",
    "ax.set_ylabel('Negative')\n",
    "\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "349a7519-836f-43bf-b341-8e2d5f3de863",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15, 10))\n",
    "\n",
    "for ctype, col in col_typeadd.items(): \n",
    "    if ('_' not in ctype) and ('DAN' in ctype): \n",
    "        sel = ornkcdanv.loc[[ctype in cell_type for cell_type in ornkcdanv.index]]\n",
    "        ax.scatter(sel.positive, sel.negative, color=col_typeadd[ctype], label=ctype, s = 50)\n",
    "\n",
    "# Add y=x dashed line\n",
    "ax.axline((0, 0), slope=1, linestyle='--', color='gray', alpha=0.6)\n",
    "# Add 'y = x' as text next to the dashed line\n",
    "ax.text(0.56, 0.8, 'y = x', fontsize=18, color='black', transform=ax.transAxes)\n",
    "\n",
    "ax.set_xlabel('Positive')\n",
    "ax.set_ylabel('Negative')\n",
    "\n",
    "# Set x and y-axis limits to start from 0\n",
    "ax.set_xlim(left=0)\n",
    "ax.set_ylim(bottom=0)\n",
    "\n",
    "ax.legend()\n",
    "ax.set_title('Olfactory input valence for Dopaminergic neurons')\n",
    "if savefig: \n",
    "    plt.savefig('/Users/yijieyin/Desktop/conferences/PDN_symposium/DAN_olf_valence.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a9eeb0-c265-4dfa-b540-17a7773b1870",
   "metadata": {},
   "source": [
    "Greg's comments:  \n",
    "for KCs that take input from multiple PNs, do they tend to be positive?  \n",
    "Davi's work: food odour related are positive  \n",
    "maybe you can see valence  \n",
    "reverse is not true: not the case for negative  \n",
    "for DANs:  \n",
    "    left/right consistent  \n",
    "    positive/negative - try other senses?  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "850b89e7-6252-4a91-b2f2-2e73c18d09b2",
   "metadata": {},
   "source": [
    "### do KCs that take input from more PNs tend to be more positive?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77acb38d-6e8f-4695-a07c-4c6fc1097b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this line converts the values to boolens, so >0 -> true, =0 -> false. Then summing across column \n",
    "ornkc.astype(bool).sum(axis=0).hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "800f610f-c948-46e5-82cb-6671fe4058b1",
   "metadata": {},
   "source": [
    "So all KCs receive direct/indirect input from all ORNs. So the question is a moo point. \n",
    "But try with direct connections from PNs? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e7a9d2-d479-4e7d-a2bd-37e6fa5cdb1b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## input from senses for KCs and DANs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e44223dd-7c61-4f55-9368-d30db883e751",
   "metadata": {},
   "source": [
    "### KCs: how much input from each senses? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7428a895-9c75-43ad-8ed3-aa512511b345",
   "metadata": {},
   "outputs": [],
   "source": [
    "kc_sensein = sensesn.loc[:,[types[skid] == 'KC' for skid in sensesn.columns]].T\n",
    "kc_sensein['cell_type'] = [types_add[skid] for skid in kc_sensein.index]\n",
    "kc_sensein['side'] = [sides[skid] for skid in kc_sensein.index]\n",
    "kc_sensein.sort_values('cell_type').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fcd4ff7-6c8c-4c9f-b854-599299efdac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "kc_sensein.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b2f773b-eeda-475c-a7a7-c34fb45714af",
   "metadata": {},
   "outputs": [],
   "source": [
    "vmin = kc_sensein.drop(['cell_type','side'], axis = 1).min().min()\n",
    "vmax = kc_sensein.drop(['cell_type','side'], axis = 1).max().max()\n",
    "\n",
    "kc_sensein_dp = kc_sensein.sort_values(['olfactory','thermo-cold','gustatory-external']).style.background_gradient(cmap='Blues', vmin = vmin, vmax = vmax)\n",
    "display(kc_sensein_dp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a23a3b3-43a8-47de-8f23-251f2a9f102f",
   "metadata": {},
   "source": [
    "### plot input from different senses for KCs and DANs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c94b166a-53a6-4996-ba3f-57305d44d34b",
   "metadata": {},
   "outputs": [],
   "source": [
    "kcdan_sensein = pd.concat([kc_sensein, dans_sensein])\n",
    "kcdan_sensein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9375091d-b830-417a-a834-95523fef03db",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_melt = [col for col in kcdan_sensein.columns if col not in ['cell_type', 'side']]\n",
    "kcdan_sensein_l = pd.melt(kcdan_sensein, id_vars=['cell_type','side'], \n",
    "                          value_vars=cols_to_melt, \n",
    "                          value_name='inprop', \n",
    "                          var_name = 'sense',\n",
    "                          ignore_index=False)\n",
    "kcdan_sensein_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7f8feb-5f64-4e7e-a76a-43d0dbae8489",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (15,20))\n",
    "sns.scatterplot(data = kcdan_sensein_l, x = 'sense', y = 'inprop',hue = 'cell_type', palette = kcdan_col, ax = ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "505750bb-ed4b-4313-ad79-1ec30c144ffc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d465044b-c9ea-4f78-9bdd-15fe009430ed",
   "metadata": {},
   "source": [
    "## enteric to DAN-j"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eca855d-de2e-423e-b93d-0191a5b42fa0",
   "metadata": {},
   "source": [
    "You can get the same neurons in catmaid by searching `enteric sensory` in CATMAID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a902dc3-6ef1-483c-be51-02323ab78005",
   "metadata": {},
   "outputs": [],
   "source": [
    "entdanj = stepsn.loc[[types_add[skid] == 'enteric' for skid in stepsn.index], \n",
    "                     [types_add[skid] == 'DAN-j1' for skid in stepsn.columns]]\n",
    "entdanj.columns = [types_add[skid]+'_'+sides[skid]+'_'+skid for skid in entdanj.columns]\n",
    "entdanj.index = [names[skid]+'_'+sides[skid]+'_'+skid for skid in entdanj.index]\n",
    "entdanj.sort_values(['DAN-j1_left_4414163', 'DAN-j1_right_4414184'], ascending=[False, False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0002b638-32ad-4619-b718-9a308165526d",
   "metadata": {},
   "outputs": [],
   "source": [
    "entdanj.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1556e96-07ff-4ede-b518-bfc0ff80ce0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "entdanj['DAN-j1_left_4414163'].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f3ed0ca-54b7-46a3-a57b-77433d2fd58f",
   "metadata": {},
   "source": [
    "The ACa 01 and 02 are annotated `sugar sensory` in CATMAID - they are the only two enteric neurons that go to the protocerebrum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ccd2b0e-e444-4054-b271-8d46373ba0fe",
   "metadata": {},
   "source": [
    "What's a normal amount of input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130ef112-7282-4a9d-91cb-059278a0c323",
   "metadata": {},
   "outputs": [],
   "source": [
    "# comparing against all sensory-non_sensory pairs \n",
    "# Prepare data according to types\n",
    "data_by_type = {}\n",
    "for skel_id in stepsn.columns:\n",
    "    this_type = types[skel_id]\n",
    "    if this_type not in data_by_type:\n",
    "        data_by_type[this_type] = []\n",
    "    data_by_type[this_type].append(stepsn[skel_id])\n",
    "\n",
    "# Concatenate data within each type\n",
    "data_by_type = {type_: np.concatenate(values) for type_, values in data_by_type.items()}\n",
    "\n",
    "# Create the stacked histogram\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "plt.hist(data_by_type.values(), label=list(data_by_type.keys()), \n",
    "        color=[typecolourdict.get(key) for key in data_by_type.keys()], alpha = 0.5,\n",
    "        histtype='barstacked', bins = 30)\n",
    "ax.hist(entdanj['DAN-j1_left_4414163'], bins=30, color='red', label='DAN-j1_left')\n",
    "\n",
    "# Label the axes\n",
    "ax.set_xlabel('Value')\n",
    "ax.set_ylabel('Frequency')\n",
    "\n",
    "# Apply log10 transformation to the axes\n",
    "# ax.set_xscale('log')\n",
    "ax.set_yscale('log')\n",
    "\n",
    "# Add the legend\n",
    "ax.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3bfab58-99fb-436c-95e1-4b9583c57659",
   "metadata": {},
   "outputs": [],
   "source": [
    "# there are actually quite a few high values here. \n",
    "long_df = stepsn.reset_index().melt(id_vars='index', var_name='post', value_name='weight')\n",
    "long_df = long_df.rename(columns={'index': 'pre'})\n",
    "long_df.sort_values('weight', ascending=False).iloc[0:100,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161e2fa6-e599-4b73-bbb9-e9b5408a3400",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DAN only \n",
    "dan_stepsn = stepsn[[col for col in stepsn.columns if 'DAN' in types_add[col]]]\n",
    "# Prepare data according to types\n",
    "data_by_type = {}\n",
    "for skel_id in dan_stepsn.columns:\n",
    "    this_type = types_add[skel_id]\n",
    "    if this_type not in data_by_type:\n",
    "        data_by_type[this_type] = []\n",
    "    data_by_type[this_type].append(dan_stepsn[skel_id])\n",
    "\n",
    "# Concatenate data within each type\n",
    "data_by_type = {type_: np.concatenate(values) for type_, values in data_by_type.items()}\n",
    "\n",
    "# Create the stacked histogram\n",
    "fig, ax = plt.subplots(figsize=(15, 10))\n",
    "\n",
    "plt.hist(data_by_type.values(), label=list(data_by_type.keys()), \n",
    "        color=[col_typeadd.get(key) for key in data_by_type.keys()], alpha = 0.3,bins = 30, \n",
    "        histtype='stepfilled')\n",
    "# ax.hist(entdanj['DAN-j1_left_4414163'], bins=30, color='red', label='DAN-j1_left_enteric', alpha = 0.8)\n",
    "# ax.hist(entdanj['DAN-j1_right_4414184'], bins=30, color='blue', label='DAN-j1_right_enteric', alpha = 0.8)\n",
    "plt.hist(entdanj, color = ['red','blue'], label = ['enteric->DAN-j1_left','enteric->DAN-j1_right'], \n",
    "        bins = 30)\n",
    "\n",
    "\n",
    "# Label the axes\n",
    "ax.set_xlabel('Input proportion for Dopaminergic neuron (\"weight\")')\n",
    "ax.set_ylabel('Number of connections (log)')\n",
    "\n",
    "# Apply log10 transformation to the axes\n",
    "# ax.set_xscale('log')\n",
    "ax.set_yscale('log')\n",
    "\n",
    "# Add the legend\n",
    "ax.legend()\n",
    "ax.set_title(\"Enteric input to DAN-j1\")\n",
    "\n",
    "if savefig: \n",
    "    plt.savefig('/Users/yijieyin/Desktop/conferences/PDN_symposium/enteric_DANj1.pdf', bbox_inches='tight')\n",
    "else: \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d40bf7a9-ffd6-4b6b-8971-8b0b380a932f",
   "metadata": {},
   "source": [
    "which interneuron? \n",
    "what's normal amount of input? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee5cc31-79ba-4e84-acb8-dd2f9ff4926e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ns = [skid for skid, name in types_add.items() if 'DAN-j1' in name]\n",
    "ins = [skid for skid, name in names.items() if ('Sens-B1-ACa-02' in name) or ('Sens-B1-ACa-01' in name)]\n",
    "# # or all enteric neurons\n",
    "# ins = [skid for skid, name in types_add.items() if 'enteric' in name]\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (15,10))\n",
    "# n has to be one skid at a time, because you can't add input proportions \n",
    "for this_n in ns: \n",
    "    ys = [] \n",
    "    for i in range(len(steps_nosense)): \n",
    "        this_step = steps_nosense[i]\n",
    "        selected_inprop = this_step.loc[this_step.index.isin(ins), this_step.columns.isin([this_n])]\n",
    "        # sum across columns / postsynaptic \n",
    "        ys.append(selected_inprop.sum(axis = 0))\n",
    "\n",
    "    # plotting \n",
    "    plt.plot([i+1 for i in range(len(steps_nosense))], \n",
    "             ys, \n",
    "             side_linetype[sides[this_n]], \n",
    "            label = sides[this_n], \n",
    "            color = 'black', \n",
    "            lw = 3)\n",
    "plt.xlabel('Number of hops in the polysynaptic chain')\n",
    "plt.ylabel('Percentage input accounted for')\n",
    "plt.legend()\n",
    "plt.title(\"DAN-j1's input from sugar-sensing neurons\")\n",
    "if savefig: \n",
    "    plt.savefig('/Users/yijieyin/Desktop/conferences/PDN_symposium/sugarsensing_DANj1.pdf', bbox_inches='tight')\n",
    "else: \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89852e54-f1b2-444d-956d-0cbaa730a7d9",
   "metadata": {},
   "source": [
    "### igraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f027ee07-fb0c-441c-b303-2a5e6eaa1c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import igraph as ig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ceb71c9-f41b-4f62-a4b5-494913ed0371",
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_matrix = ad_inprop.copy()\n",
    "\n",
    "# Convert adjacency matrix to igraph.Graph object\n",
    "g = ig.Graph.Weighted_Adjacency(adj_matrix.values.tolist())\n",
    "g.es['weight'] = adj_matrix.values[adj_matrix.values.nonzero()]\n",
    "g.vs['skid'] = adj_matrix.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce72df7-688a-4358-ab79-4f583344855b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to calculate the total weight of a path\n",
    "def total_weight(graph, path):\n",
    "    weight = 1\n",
    "    for i in range(len(path) - 1):\n",
    "        weight *= graph[path[i], path[i+1]]\n",
    "    return weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b6df31c-9216-4d0c-ba28-a9defab86de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the neurons and the maximum number of steps allowed\n",
    "source_neurons = [key for key, v in names.items() if ('Sens-B1-ACa-01' in v) or ('Sens-B1-ACa-02' in v)]\n",
    "target_neurons = [key for key, v in types_add.items() if v == 'DAN-j1']\n",
    "max_steps = 4\n",
    "\n",
    "# Iterate through all paths between the given neurons and calculate the total weight for each path\n",
    "all_paths = []\n",
    "for source in tqdm(source_neurons):\n",
    "    for target in target_neurons:\n",
    "        simple_paths = g.get_all_simple_paths(g.vs.find(skid=source).index, \n",
    "                                              g.vs.find(skid=target).index, \n",
    "                                              cutoff=max_steps)\n",
    "        for path in simple_paths:\n",
    "            if len(path) <= max_steps + 1:  # +1 because the path includes the source neuron\n",
    "                weight = total_weight(g, path)\n",
    "                all_paths.append((path, weight))\n",
    "all_paths.sort(key = lambda tup: tup[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c1a988-d6b8-4a0f-9052-1ffaae986786",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "[(path, weight) for path, weight in all_paths if weight>0.005]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1e0d3a-f56e-4f5d-b28c-9d4ad786b178",
   "metadata": {},
   "outputs": [],
   "source": [
    "# direct connections \n",
    "[(path, weight) for path, weight in all_paths if len(path)==2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b852ee-6d56-41d6-8769-40fe1dfa36d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "onehop = [(path, weight) for path, weight in all_paths if len(path)==3]\n",
    "mid = [(path[1], weight) for path, weight in onehop]\n",
    "# Initialize an empty dictionary to store the sums\n",
    "sums = {}\n",
    "sums_skid = {}\n",
    "\n",
    "# Iterate through the list of tuples\n",
    "for key, value in mid:\n",
    "    skid = g.vs[key]['skid']\n",
    "    # If the key is not in the dictionary, add it with the value as the initial sum\n",
    "    if key not in sums:\n",
    "        sums[key] = value\n",
    "        sums_skid[skid] = value\n",
    "    # If the key is already in the dictionary, add the value to the existing sum\n",
    "    else:\n",
    "        sums[key] += value\n",
    "        sums_skid[skid] += value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf6baf7a-9c54-4d5b-8082-63be5736ac74",
   "metadata": {},
   "outputs": [],
   "source": [
    "sums_skid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf92857-01c1-4d38-a591-2526670689cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "[(names[skid],weight) for skid, weight in sums_skid.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9cefc17-6133-4b4a-ae8c-de84f29c0764",
   "metadata": {},
   "outputs": [],
   "source": [
    "names[g.vs[848]['skid']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc97ce7-9c10-4762-95d5-1a0ca7439624",
   "metadata": {},
   "outputs": [],
   "source": [
    "types_add[g.vs[1524]['skid']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f18682-a14a-4042-b91d-bc156dd89c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "inonehop = [(path, round(weight, 5)) for path, weight in all_paths if len(path)<=3]\n",
    "# Create a directed graph\n",
    "G = nx.DiGraph()\n",
    "\n",
    "# Iterate through the strong_paths and add edges to the graph\n",
    "for path, weight in inonehop:\n",
    "    if len(path) <= 3:\n",
    "        for i in range(len(path) - 1):\n",
    "            G.add_edge(path[i], path[i + 1], weight=weight)\n",
    "\n",
    "# Assign the 'layer' attribute to the nodes\n",
    "for node in G.nodes:\n",
    "    name = types_add[g.vs[node]['skid']]\n",
    "    if name == 'enteric':\n",
    "        G.nodes[node][\"layer\"] = 0\n",
    "    elif name == 'DAN-j1':\n",
    "        G.nodes[node][\"layer\"] = 2\n",
    "    else:\n",
    "        G.nodes[node][\"layer\"] = 1\n",
    "\n",
    "# Normalize the weights to a suitable range for edge thickness (e.g., between 1 and 5)\n",
    "weights = [weight for path, weight in inonehop]\n",
    "scaled_weights = [(w - min(weights)) / (max(weights) - min(weights)) * 4 + 1 for w in weights]\n",
    "\n",
    "# Create a layout for the nodes\n",
    "pos = nx.multipartite_layout(G, subset_key=\"layer\")\n",
    "\n",
    "# Adjust the vertical position of the first and last layers\n",
    "vertical_spacing = 0.2\n",
    "for node, coords in pos.items():\n",
    "    if G.nodes[node][\"layer\"] == 0:\n",
    "        pos[node] = (coords[0], coords[1] - vertical_spacing)\n",
    "    elif G.nodes[node][\"layer\"] == 2:\n",
    "        pos[node] = (coords[0], coords[1] + vertical_spacing)\n",
    "\n",
    "# Draw the graph with edge thickness representing the weights\n",
    "fig, ax = plt.subplots(figsize = (20,20))\n",
    "nx.draw(G, pos, with_labels=True, node_color=\"lightblue\", edge_color=\"gray\", font_weight=\"bold\", node_size=1000, width=scaled_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2977e7f-27c6-4c5d-b299-edd7c4d87e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for node in G.nodes: \n",
    "    print(types[g.vs[node]['skid']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b89cda-504b-4fd7-8c97-76eb52a1c341",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db43dfa5-e9d4-4cbe-bfbc-24081cabecc9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e7ef799-ead5-4a37-9256-7fcda03b561c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f31bed4b-7523-4ed6-a98e-e8ff704a3ad4",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Hugin interneuron \n",
    "Hugin PC especially, relevant in bitter taste, also responsible for sensing infection and then stopping the larvae from eating - from [Surendran et al. 2017](https://journals.biologists.com/jeb/article/220/10/1774/17783/Pathogen-induced-food-evasion-behavior-in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8df238-4cea-467c-8ae8-d6ec4d627bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymaid\n",
    "rm = pymaid.connect_catmaid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd8b097-d31c-45a6-8c66-afdfadbbe1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "hugin = pymaid.find_neurons(annotations='Hugin PC')\n",
    "hugin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f68c71-4945-4b08-b32e-9c96056944c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# seems like these neurons are not in the ad connectome \n",
    "[skid in types for skid in hugin.skeleton_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ffbe30f-d6ec-442c-b8ab-081367f73cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af434f6-4445-4748-87e4-db98efd110e5",
   "metadata": {},
   "source": [
    "meta annotation: 'papers' - all the published papers.  \n",
    "Winding et al., Schlegel 2016, Miroschnikow 2017/2018 - then you should get all the neurons. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a796df78-62b8-4af7-8da8-8ffb59cdd956",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f198bf-fb35-4ddf-a8e5-c666b32737ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5e62802d-4e1a-4519-8294-ad694e47a10d",
   "metadata": {},
   "source": [
    "This relates to a broader problem: how to relate any neuron to any neuron in the same way as relating sensory neurons to any neuron? I think it has to do with the initial matrix in matrix multiplications. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a6235d-f770-4eb4-a399-4c119195b24d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a8c536-0874-4935-af4b-88c2508d51d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb9d88a-de6c-48ba-86dd-c164992f5d48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf605a0-6fb6-4e3a-b553-b260d650cf7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e1cb0f-13fa-4c43-9cb8-34e90260244b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9706d0aa-3001-46c9-bb5a-685fd6506e98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4808cbb-bec7-4c1e-b6cb-2dc497114130",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0a61656f-4b77-4521-89af-0e3b0d2e86ad",
   "metadata": {},
   "source": [
    "TODO: \n",
    "group columns by pairs  \n",
    "name the skids \n",
    "\n",
    "5 VPNs, they connect little to KCs   \n",
    "Jiaqi chen: model of the visual lobe  \n",
    "KCs & DANs: are the senses represented in a similar way?  \n",
    "Cold go to KCs and warm not sure  \n",
    "warm -> broad, from all ORNs, and warm sensors, olfaction depends on temperature  \n",
    "cold: from a few PNs, then go straight upstairs   \n",
    "https://www.science.org/doi/full/10.1126/sciadv.abg6707 \n",
    "\n",
    "\n",
    "72, 73 KCs on either side  \n",
    "how do you compare the input from KCs and DANs?  \n",
    "some KCs specialise in thermo  \n",
    "representation different from valence extraction? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2985c4f9-da07-46e3-a57b-34a4149af6d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "toc-autonumbering": true,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
