{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.sparse import csc_matrix, coo_matrix, diags\n",
    "import scipy as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = pd.read_feather('C:\\\\Users\\\\44745\\\\Documents\\\\malevnc_inputs.feather')\n",
    "output = pd.read_feather(\n",
    "    'C:\\\\Users\\\\44745\\\\Documents\\\\malevnc_outputs.feather')\n",
    "meta = pd.read_csv('C:\\\\Users\\\\44745\\\\Documents\\\\manc_meta.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs.bodyid = inputs.bodyid.astype('Int64')\n",
    "output.bodyid = output.bodyid.astype('Int64')\n",
    "inputs.partner = inputs.partner.astype('Int64')\n",
    "output.partner = output.partner.astype('Int64')\n",
    "\n",
    "# filter to only consider bodyids in meta \n",
    "inputs = inputs[inputs.bodyid.isin(meta.bodyid) & inputs.partner.isin(meta.bodyid)]\n",
    "output = output[output.bodyid.isin(meta.bodyid) & output.partner.isin(meta.bodyid)] \n",
    "\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta['combined_type'] = meta.instance \n",
    "meta.combined_type.fillna(meta.bodyid.astype(str), inplace=True)\n",
    "\n",
    "meta['nt_binary'] = meta.predicted_nt.apply(\n",
    "    lambda x: 1 if x == 'acetylcholine' else -1)\n",
    "meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ntcount_perinstance = meta.groupby('instance')['nt_binary'].nunique()\n",
    "# neurons with multiple nt\n",
    "diffnt = ntcount_perinstance[ntcount_perinstance > 1]\n",
    "diffnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_to_combined_type = dict(zip(meta.bodyid, meta.combined_type))\n",
    "instance_to_nt_binary = dict(zip(meta.instance, meta.nt_binary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardise nt_binary for neurons with multiple nt\n",
    "# count the number of +/- neurons for each instance\n",
    "nt_count_per_instance = meta[meta.instance.isin(diffnt.index)].groupby('instance')['nt_binary'].value_counts().reset_index(name='n_neurons')\n",
    "\n",
    "for inst in nt_count_per_instance.instance.unique(): \n",
    "    df = nt_count_per_instance[nt_count_per_instance.instance == inst].copy()\n",
    "    df.sort_values('n_neurons', ascending=False, inplace=True)\n",
    "    # if there is a max count, use the corresponding nt_binary\n",
    "    if df.n_neurons.iloc[0] > df.n_neurons.iloc[1]:\n",
    "        instance_to_nt_binary[inst] = df.nt_binary.iloc[0]\n",
    "    # if there is a tie, randomly choose one\n",
    "    else:\n",
    "        instance_to_nt_binary[inst] = df.nt_binary.sample(1).values[0]\n",
    "\n",
    "meta['nt_binary'] = meta.instance.map(instance_to_nt_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_conn = inputs.rename(columns={'bodyid':'post', 'partner':'pre'})\n",
    "out_conn = output.rename(\n",
    "    columns={'bodyid': 'pre', 'partner': 'post'})\n",
    "\n",
    "conn = pd.concat([in_conn[['pre', 'post', 'weight']], out_conn[[\n",
    "                 'pre', 'post', 'weight']]], ignore_index=True).drop_duplicates()\n",
    "conn = conn[conn.weight > 0]\n",
    "conn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_level = False \n",
    "\n",
    "if type_level:\n",
    "    conntt = conn.copy()\n",
    "    conntt['pre_type'] = conntt.pre.map(id_to_combined_type)\n",
    "    conntt['post_type'] = conntt.post.map(id_to_combined_type)\n",
    "    # connectivity between combined_types\n",
    "    conntt = conntt.groupby(['pre_type', 'post_type']).weight.sum().reset_index()\n",
    "    \n",
    "    # instead of making a dense matrix based on the edgelist above, let's make a sparse one from the edgelist directly\n",
    "    # first make a coo matrix\n",
    "    nodes = set(meta.combined_type)\n",
    "    sorted_nodes = sorted(nodes)  # Convert the set to a sorted list\n",
    "    nodes_to_idx = {node: int(num) for num, node in enumerate(sorted_nodes)}\n",
    "\n",
    "    # type to type connttectivity\n",
    "    conntt['pre_idx'] = conntt['pre_type'].map(nodes_to_idx)\n",
    "    conntt['post_idx'] = conntt['post_type'].map(nodes_to_idx)\n",
    "\n",
    "    # Create COO matrix\n",
    "    row = conntt['pre_idx'].values\n",
    "    col = conntt['post_idx'].values\n",
    "    data = conntt['weight'].values\n",
    "    matrix_size = len(nodes)\n",
    "    coo = coo_matrix((data, (row, col)), shape=(matrix_size, matrix_size))\n",
    "else: \n",
    "    # instead of making a dense matrix based on the edgelist above, let's make a sparse one from the edgelist directly\n",
    "    # first make a coo matrix\n",
    "    nodes = set(meta.bodyid)\n",
    "    sorted_nodes = sorted(nodes)  # Convert the set to a sorted list\n",
    "    nodes_to_idx = {node:int(num) for num, node in enumerate(sorted_nodes)}\n",
    "\n",
    "    # type to type connectivity\n",
    "    conn['pre_idx'] = conn['pre'].map(nodes_to_idx)\n",
    "    conn['post_idx'] = conn['post'].map(nodes_to_idx)\n",
    "\n",
    "    # Create COO matrix\n",
    "    row = conn['pre_idx'].values\n",
    "    col = conn['post_idx'].values\n",
    "    data = conn['weight'].values\n",
    "    matrix_size = len(nodes)\n",
    "    coo = coo_matrix((data, (row, col)), shape=(matrix_size, matrix_size))\n",
    "# then turn it into csc matrix\n",
    "csc = coo.tocsc()\n",
    "\n",
    "csc_size = csc.data.nbytes  # Size of the data array\n",
    "csc_size += csc.indices.nbytes  # Size of the indices array\n",
    "csc_size += csc.indptr.nbytes  # Size of the index pointer array\n",
    "# number of MB\n",
    "csc_size/1e6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_sums = csc.sum(axis=0)\n",
    "# Handling division by zero in case some columns have a sum of zero\n",
    "# that is, where a neuron doesn't have incoming synapses\n",
    "# .A turns it from a sparse matrix into a dense np array\n",
    "col_sums_with_inversion = np.reciprocal(col_sums.A.squeeze().astype(float), where=col_sums.A.squeeze() != 0)\n",
    "# Multiply each column by the inverse of its sum\n",
    "inprop = csc.multiply(col_sums_with_inversion)\n",
    "# and then reduce the precision to float32 to save memory\n",
    "inprop = inprop.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if type_level:\n",
    "    sp.sparse.save_npz('data/manc_type_inprop.npz', inprop)\n",
    "else:\n",
    "    sp.sparse.save_npz('data/manc_inprop.npz', inprop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if type_level: \n",
    "    meta['idx'] = meta.combined_type.map(nodes_to_idx)\n",
    "    # get the unique rows\n",
    "    meta_type = meta.drop('bodyid', axis=1).drop_duplicates()\n",
    "    meta_type.to_csv('data/manc_type_meta.csv')\n",
    "    \n",
    "else: \n",
    "    meta['idx'] = meta.bodyid.map(nodes_to_idx)\n",
    "    meta.to_csv('data/manc_meta.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
